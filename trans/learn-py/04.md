# 第五章。节省时间和内存

|  | *“不是每天增加，而是每天减少。砍掉不必要的东西。”* |  |
|  | --*李小龙* |

我喜欢李小龙的这句话，他真是个聪明人！特别是，第二部分，*对不必要的*进行黑客攻击，对我来说，是什么让计算机程序变得优雅。毕竟，如果有更好的方式来做事，这样我们就不会浪费时间和记忆，为什么不呢？

有时，没有将代码提升到最大限度是有正当理由的：例如，有时为了实现微不足道的改进，我们不得不牺牲可读性或可维护性。当我们可以在 1.05 秒内用可读、干净的代码提供网页时，用不可读、复杂的代码在 1 秒内提供网页有意义吗？不，这毫无意义。

另一方面，有时尝试从函数中减去一毫秒是完全合法的，特别是当函数要被调用数千次时。您在那里保存的每一毫秒意味着每千次调用保存一秒钟，这对您的应用程序可能很有意义。

鉴于这些考虑，本章的重点将不是提供工具，让您“无论发生什么”都能将代码推向性能和优化的绝对极限，而是提供工具，让您编写高效、优雅的代码，这些代码读起来很好，运行速度快，并且不会以明显的方式浪费资源。

在本章中，我将进行一些测量和比较，并谨慎地得出一些结论。请记住，在具有不同设置或不同操作系统的不同盒子上，结果可能会有所不同。请看下面的代码：

`squares.py`

```
def square1(n):
    return n ** 2  # squaring through the power operator

def square2(n):
    return n * n  # squaring through multiplication
```

两个函数都返回*n*的平方，但哪个更快？从我在他们身上运行的一个简单的基准测试来看，第二个看起来稍微快一点。如果你仔细想想，这是有道理的：计算一个数字的幂涉及到乘法，因此，无论你使用什么算法来执行幂运算，它都不可能打败像`square2`中那样的简单乘法。

我们关心这个结果吗？在大多数情况下不会。如果你正在编写一个电子商务网站，很可能你甚至不需要将一个数字提高到二次方，如果你这样做，你可能需要在每页上做几次。您无需担心在调用几次的函数上节省几微秒。

那么，优化何时变得重要？一种非常常见的情况是，您必须处理大量数据。如果你在一百万个`customer`对象上应用相同的函数，那么你希望你的函数被调整到最佳状态。在一个名为一百万次的函数上获得 1/10 秒可以节省 100000 秒，也就是 27.7 小时。那不一样，对吧？所以，让我们关注集合，看看 Python 为您提供了哪些工具来高效、优雅地处理它们。

### 注

我们将在本章中看到的许多概念都是基于**迭代器**和**iterable**的概念。简单地说，对象在被请求时返回其下一个元素，并在耗尽时引发`StopIteration`异常的能力。我们将在下一章中看到如何编写自定义迭代器和 iterable 对象。

# 映射、压缩和过滤器

我们将从开始回顾`map`、`filter`和`zip`，这是处理集合时可以使用的主要内置函数，然后我们将学习如何使用两个非常重要的结构实现相同的结果：**理解**和**生成器**系好安全带！

## 地图

根据官方 Python 文档：

> *`map(function, iterable, ...)`返回一个迭代器，该迭代器将函数应用于 iterable 的每个项，并生成结果。若传递了额外的 iterable 参数，那个么函数必须接受那个么多的参数，并并行应用于所有 iterable 中的项。对于多个 iterable，迭代器在最短 iterable 耗尽时停止。*

我们将在本章后面解释屈服的概念。现在，让我们将其转换为代码：我们将使用一个*lambda*函数，该函数接受数量可变的位置参数，并将它们作为元组返回。此外，由于`map`返回一个迭代器，我们需要将每个对它的调用包装在`list`构造函数中，这样我们就可以通过将 iterable 的所有元素放入一个列表来耗尽 iterable（您将在代码中看到一个例子）：

`map.example.py`

```
>>> map(lambda *a: a, range(3))  # without wrapping in list...
<map object at 0x7f563513b518>  # we get the iterator object
>>> list(map(lambda *a: a, range(3)))  # wrapping in list...
[(0,), (1,), (2,)]  # we get a list with its elements
>>> list(map(lambda *a: a, range(3), 'abc'))  # 2 iterables
[(0, 'a'), (1, 'b'), (2, 'c')]
>>> list(map(lambda *a: a, range(3), 'abc', range(4, 7)))  # 3
[(0, 'a', 4), (1, 'b', 5), (2, 'c', 6)]
>>> # map stops at the shortest iterator
>>> list(map(lambda *a: a, (), 'abc'))  # empty tuple is shortest
[]
>>> list(map(lambda *a: a, (1, 2), 'abc'))  # (1, 2) shortest
[(1, 'a'), (2, 'b')]
>>> list(map(lambda *a: a, (1, 2, 3, 4), 'abc'))  # 'abc' shortest
[(1, 'a'), (2, 'b'), (3, 'c')]

```

在前面的代码中，您可以看到为什么为了向您展示结果，我必须将对`map`的调用包装在`list`构造函数中，否则我会得到`map`对象的字符串表示形式，这在上下文中并不是很有用，是吗？

您还可以注意到每个 iterable 的元素是如何应用于函数的：首先是每个 iterable 的第一个元素，然后是每个 iterable 的第二个元素，依此类推。还要注意，当我们称之为 map 的最短的 iterables 耗尽时，map 停止。这实际上是一个非常好的行为：它不会强迫我们将所有的 iterables 调整到一个共同的长度，如果它们的长度不同，它也不会中断。

当您必须对一个或多个对象集合应用相同的函数时，`map`非常有用。作为一个更有趣的例子，让我们看看**修饰排序不修饰**成语（也称为**施瓦茨变换**。这是一种技术，在 Python 排序不提供*关键函数*时非常流行，因此今天使用较少，但这是一种很酷的技巧，偶尔也会出现。

让我们在下一个例子中看到它的一个变体：我们希望按照学生累积的学分总和降序排序，以便让最好的学生位于 0 位。我们编写一个函数来生成一个装饰过的对象，我们进行排序，然后取消装饰。每个学生都有三门（可能不同）科目的学分。装饰一个对象意味着对其进行转换，或者向其添加额外的数据，或者将其放入另一个对象中，以允许我们能够按照我们想要的方式对原始对象进行排序。排序后，我们还原装饰对象以从中获取原始对象。这被称为去装饰。

`decorate.sort.undecorate.py`

```
students = [
    dict(id=0, credits=dict(math=9, physics=6, history=7)),
    dict(id=1, credits=dict(math=6, physics=7, latin=10)),
    dict(id=2, credits=dict(history=8, physics=9, chemistry=10)),
    dict(id=3, credits=dict(math=5, physics=5, geography=7)),
]

def decorate(student):
    # create a 2-tuple (sum of credits, student) from student dict
    return (sum(student['credits'].values()), student)

def undecorate(decorated_student):
    # discard sum of credits, return original student dict
    return decorated_student[1]

students = sorted(map(decorate, students), reverse=True)
students = list(map(undecorate, students))
```

在前面的代码中，我强调了棘手和重要的部分。让我们从了解每个学生对象是什么开始。事实上，让我们打印第一个：

`{'credits': {'history': 7, 'math': 9, 'physics': 6}, 'id': 0}`

你可以看到这是一本有两个键的字典：`id`和`credit`。`credit`的值也是一个字典，其中有三个主题/年级键/值对。我相信您还记得我们在数据结构领域的访问，调用`dict.values()`返回一个类似于`iterable`的对象，只有值。因此，对于第一个学生来说，`sum(student['credits'].values())`相当于`sum(9, 6, 7)`（或者这些数字的任何排列，因为字典不保留顺序，但幸运的是，加法是可交换的）。

有了这些，我们就很容易看到和任何一个学生打电话装饰的结果。打印`decorate(students[0])`的结果：

`(22, {'credits': {'history': 7, 'math': 9, 'physics': 6}, 'id': 0})`

太好了！如果我们像这样装饰所有学生，我们可以根据他们的总学分对他们进行排序，但只需对元组列表进行排序。为了将装饰应用于学生的每个项目，我们称之为`map(decorate, students)`。然后我们对结果进行排序，然后以类似的方式取消装饰。如果您正确地阅读了前面的章节，那么理解这段代码应该不会太难。

运行整个代码后打印学生会产生：

```
$ python decorate.sort.undecorate.py
[{'credits': {'chemistry': 10, 'history': 8, 'physics': 9}, 'id': 2},
 {'credits': {'latin': 10, 'math': 6, 'physics': 7}, 'id': 1},
 {'credits': {'history': 7, 'math': 9, 'physics': 6}, 'id': 0},
 {'credits': {'geography': 7, 'math': 5, 'physics': 5}, 'id': 3}]

```

你可以看到，按照学生对象的顺序，他们确实是按照学分的总和排序的。

### 注

关于*修饰-排序-取消修饰*习惯用法的更多信息，在官方 Python 文档（[的排序操作部分有一个非常好的介绍 https://docs.python.org/3.4/howto/sorting.html#the-旧方法使用装饰分类不装饰](https://docs.python.org/3.4/howto/sorting.html#the-old-way-using-decorate-sort-undecorate)。

关于排序部分，有一点需要注意：如果两个或两个以上的学生共享同一个总数会怎么样？排序算法随后将通过相互比较`student`对象来对元组进行排序。这没有任何意义，在更复杂的情况下，可能会导致不可预测的结果，甚至错误。如果您想确保避免这个问题，一个简单的解决方案是创建一个 3 元组而不是 2 元组，第一个位置是积分之和，第二个位置是`students`列表中`student`对象的位置，第三个位置是`student`对象本身。这样，如果积分总和相同，元组将根据位置进行排序，位置总是不同的，因此足以解决任何一对元组之间的排序问题。有关此主题的更多注意事项，请查看官方 Python 文档中的排序操作部分。

## 拉链

在前面的章节中我们已经介绍了和`zip`，所以让我们正确地定义它，然后我想向您展示如何将它与`map`结合起来。

根据 Python 文档：

> *`zip(*iterables)`返回元组迭代器，其中第 i 个元组包含来自每个参数序列或 iterables 的第 i 个元素。当最短输入 iterable 耗尽时，迭代器停止。对于单个 iterable 参数，它返回一个 1 元组的迭代器。如果没有参数，它将返回一个空迭代器。*

让我们看一个例子：

`zip.grades.py`

```
>>> grades = [18, 23, 30, 27, 15, 9, 22]
>>> avgs = [22, 21, 29, 24, 18, 18, 24]
>>> list(zip(avgs, grades))
[(22, 18), (21, 23), (29, 30), (24, 27), (18, 15), (18, 9), (24, 22)]
>>> list(map(lambda *a: a, avgs, grades))  # equivalent to zip
[(22, 18), (21, 23), (29, 30), (24, 27), (18, 15), (18, 9), (24, 22)]

```

在前面的代码中，我们将每个学生上一次考试的平均成绩和分数压缩在一起。请注意，两个列表调用中的代码如何产生完全相同的结果，这表明使用`map`复制`zip`是多么容易。还要注意，正如我们对`map`所做的那样，我们必须将`zip`调用的结果提供给`list`构造函数。

关于组合使用`map`和`zip`的一个简单示例可以是一种计算序列中元素最大值的方法，即每个序列的第一个元素的最大值，然后是第二个元素的最大值，依此类推：

`maxims.py`

```
>>> a = [5, 9, 2, 4, 7]
>>> b = [3, 7, 1, 9, 2]
>>> c = [6, 8, 0, 5, 3]
>>> maxs = map(lambda n: max(*n), zip(a, b, c))
>>> list(maxs)
[6, 9, 2, 9, 7]

```

请注意，计算三个序列的最大值是多么容易。`zip`不是严格需要的，当然，我们可以只使用`map`，但这需要我们编写一个更复杂的函数来为`map`提供信息。有时，我们甚至不可能将我们提供的功能更改为`map`。在这种情况下，能够对数据进行按摩（就像我们在本例中使用`zip`所做的那样）非常有用。

## 过滤器

根据Python 文档：

> *`filter(function, iterable)`从 iterable 的那些元素构造一个迭代器，函数为其返回 True。iterable 可以是序列、支持迭代的容器或迭代器。如果函数为`None`，则假定标识函数，即删除 iterable 中所有为 false 的元素。*

让我们看一个非常简单的例子：

`filter.py`

```
>>> test = [2, 5, 8, 0, 0, 1, 0]
>>> list(filter(None, test))
[2, 5, 8, 1]
>>> list(filter(lambda x: x, test))  # equivalent to previous one
[2, 5, 8, 1]
>>> list(filter(lambda x: x > 4, test))  # keep only items > 4
[5, 8]

```

在前面的代码中，请注意对 filter 的第二次调用与第一次调用是如何等效的。如果我们传递一个接受一个参数并返回参数本身的函数，则只有那些为`True`的参数才会使函数返回`True`，因此此行为与传递`None`完全相同。模仿一些内置 Python 行为通常是一个很好的练习。当您成功时，可以说您完全理解 Python 在特定情况下的行为。

用`map`、`zip`和`filter`（以及 Python 标准库中的其他几个函数）武装，我们可以非常有效地按摩序列。但这些功能并不是实现这一目标的唯一途径。让我们看看 Python 最优秀的特性之一：理解。

# 理解

Python提供了不同类型的理解：`list`、`dict`和`set`。

现在我们将集中讨论第一个问题，然后很容易解释其他两个问题。

理解是一种快速列出清单的方法。通常，列表是某些操作的结果，这些操作可能涉及应用函数、筛选或构建不同的数据结构。

让我们从一个非常简单的例子开始，我想用前 10 个自然数的平方来计算一个列表。你会怎么做？有两种等效方法：

`squares.map.py`

```
# If you code like this you are not a Python guy! ;)
>>> squares = []
>>> for n in range(10):
...     squares.append(n ** 2)
...
>>> list(squares)
[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]

# This is better, one line, nice and readable
>>> squares = map(lambda n: n**2, range(10))
>>> list(squares)
[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]

```

前面的例子对您来说应该不是什么新鲜事。让我们看看如何使用列表理解实现相同的结果：

`squares.comprehension.py`

```
>>> [n ** 2 for n in range(10)]
[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]

```

就这么简单。这不是很优雅吗？基本上我们在方括号内放了一个`for`循环。现在让我们过滤掉奇数的方块。我将演示如何使用`map`和`filter`，然后再次使用`list`理解。

`even.squares.py`

```
# using map and filter
sq1 = list(
    filter(lambda n: not n % 2, map(lambda n: n ** 2, range(10)))
)
# equivalent, but using list comprehensions
sq2 = [n ** 2 for n in range(10) if not n % 2]

print(sq1, sq1 == sq2)  # prints: [0, 4, 16, 36, 64] True
```

我认为现在可读性上的差异是显而易见的。这份清单读起来好多了。这几乎是英语：如果 n 是偶数，请给我 0 到 9 之间的*n*的所有正方形（*n**2*）。

根据 Python 文档：

> *列表理解由括号组成，括号中包含一个表达式，后跟一个`for`子句，然后是零个或多个`for`或`if`子句。结果将是一个新的列表，该列表是在其后面的`for`和`if`子句的上下文中对表达式求值的结果。“*

## 嵌套理解

我们来看一个嵌套循环的例子。在处理算法时，必须使用两个占位符在序列上迭代是非常常见的。第一个从左到右贯穿整个序列。第二个也是，但它从第一个开始，而不是 0。其概念是在不重复的情况下测试所有对。让我们看看经典的`for`循环等价物。

`pairs.for.loop.py`

```
items = 'ABCDE'
pairs = []
for a in range(len(items)):
    for b in range(a, len(items)):
        pairs.append((items[a], items[b]))
```

如果在末尾打印对，则会得到：

```
[('A', 'A'), ('A', 'B'), ('A', 'C'), ('A', 'D'), ('A', 'E'), ('B', 'B'), ('B', 'C'), ('B', 'D'), ('B', 'E'), ('C', 'C'), ('C', 'D'), ('C', 'E'), ('D', 'D'), ('D', 'E'), ('E', 'E')]

```

所有具有相同字母的元组都是那些`b`与`a`位于相同位置的元组。现在，让我们看看如何在列表理解中翻译这一点：

`pairs.list.comprehension.py`

```
items = 'ABCDE'
pairs = [(items[a], items[b])
    for a in range(len(items)) for b in range(a, len(items))]
```

这个版本只有两行，达到了相同的效果。注意，在这个特殊的情况下，因为`for`循环`b`依赖于`a`，所以在理解中它必须遵循`for`循环`a`。如果你交换它们，你会得到一个名称错误。

## 过滤理解力

我们可以将过滤应用于理解。我们先用`filter`来做。让我们找出所有短边小于 10 的毕达哥拉斯三元组。显然，我们不想对组合进行两次测试，因此我们将使用上一个示例中看到的技巧。

### 注

A**毕达哥拉斯三元组**是满足方程式![Filtering a comprehension](images/4715_05_03.jpg)的整数的三元组（*A*、*b*、*c*。

`pythagorean.triple.py`

```
from math import sqrt
# this will generate all possible pairs
mx = 10
legs = [(a, b, sqrt(a**2 + b**2))
    for a in range(1, mx) for b in range(a, mx)]
# this will filter out all non pythagorean triples
legs = list(
    filter(lambda triple: triple[2].is_integer(), legs))
print(legs)  # prints: [(3, 4, 5.0), (6, 8, 10.0)]
```

在前面的代码中，我们生成了一个包含*3 元组*的腿的列表。每个元组包含两个整数（腿）和毕达哥拉斯三角形的斜边，毕达哥拉斯三角形的腿是元组中的前两个数字。例如，当 a=3 和 b=4 时，元组将是（3,4,5.0），当 a=5 和 b=7 时，元组将是（5,7,8.602325267042627）。

完成所有三元组后，我们需要过滤掉所有没有斜边的整数。为此，我们根据`float_number.is_integer()`为`True`的情况进行过滤。这意味着在我之前展示的两个示例元组中，斜边为 5.0 的元组将被保留，而斜边为 8.602325267042627 的元组将被丢弃。

这很好，但我不喜欢三元组有两个整数和一个浮点数。它们应该都是整数，所以让我们使用 map 来解决这个问题：

`pythagorean.triple.int.py`

```
from math import sqrt
mx = 10
legs = [(a, b, sqrt(a**2 + b**2))
    for a in range(1, mx) for b in range(a, mx)]
legs = filter(lambda triple: triple[2].is_integer(), legs)
# this will make the third number in the tuples integer
legs = list(
    map(lambda triple: triple[:2] + (int(triple[2]), ), legs))
print(legs)  # prints: [(3, 4, 5), (6, 8, 10)]
```

注意我们添加的步骤。我们把每个元素放在腿上，然后切片，只取其中的前两个元素。然后，我们将切片与一个 1 元组连接起来，在这个元组中，我们放置了我们不喜欢的浮点数的整数版本。

好像要做很多工作，对吧？的确如此。让我们看看如何通过列表理解完成所有这些：

`pythagorean.triple.comprehension.py`

```
from math import sqrt
# this step is the same as before
mx = 10
legs = [(a, b, sqrt(a**2 + b**2))
    for a in range(1, mx) for b in range(a, mx)]
# here we combine filter and map in one CLEAN list comprehension
legs = [(a, b, int(c)) for a, b, c in legs if c.is_integer()]
print(legs)  # prints: [(3, 4, 5), (6, 8, 10)]
```

我知道。好多了，不是吗？它干净、可读、简短。换句话说，优雅。

### 提示

我在这里讲得很快，正如在上一章的总结中所预期的那样。你在玩这个代码吗？如果没有，我建议你这样做。这是非常重要的，你玩，打破东西，改变事情，看看会发生什么。确保你清楚地了解正在发生的事情。你想成为忍者，对吗？

## 听写理解

字典和集合理解的工作原理与列表完全相同，只是语法上有一点不同。以下示例足以解释您需要了解的所有内容：

`dictionary.comprehensions.py`

```
from string import ascii_lowercase
lettermap = dict((c, k) for k, c in enumerate(ascii_lowercase, 1))
```

如果您打印`lettermap`，您将看到以下内容（我省略了中间的结果，您得到了要点）：

```
{'a': 1,
 'b': 2,
 'c': 3,
 ... omitted results ...
 'x': 24,
 'y': 25,
 'z': 26}

```

在前面的代码中发生的是，我们正在向`dict`构造函数提供理解（从技术上讲，是一个生成器表达式，我们稍后会看到）。我们告诉`dict`构造函数从理解中的每个元组中生成*键/值*对。我们使用`enumerate`枚举所有小写 ASCII 字母的序列，从*1*开始。小菜一碟。还有另一种方法可以做同样的事情，更接近于其他字典语法：

```
lettermap = {c: k for k, c in enumerate(ascii_lowercase, 1)}
```

它做了完全相同的事情，使用了稍微不同的语法，突出了更多的*键：值*部分。

字典不允许在键中重复，如以下示例所示：

`dictionary.comprehensions.duplicates.py`

```
word = 'Hello'
swaps = {c: c.swapcase() for c in word}
print(swaps)  # prints: {'o': 'O', 'l': 'L', 'e': 'E', 'H': 'h'}
```

我们创建了一个字典，其中包含键、字符串`'Hello'`中的字母以及相同字母的值，但大小写交换。请注意，只有一对`'l': 'L'`。构造函数不会抱怨，只是将副本重新分配到最新的值。让我们用另一个例子来说明这一点；让我们为每个键指定其在字符串中的位置：

`dictionary.comprehensions.positions.py`

```
word = 'Hello'
positions = {c: k for k, c in enumerate(word)}
print(positions)  # prints: {'l': 3, 'o': 4, 'e': 1, 'H': 0}
```

请注意与字母`'l': 3`关联的值。该对`'l': 2`不存在，已被`'l': 3`覆盖。

## 集合理解

集合理解与列表和字典理解非常相似。Python 既允许使用`set()`构造函数，也允许使用显式`{}`语法。让我们看一个简单的例子：

`set.comprehensions.py`

```
word = 'Hello'
letters1 = set(c for c in word)
letters2 = {c for c in word}
print(letters1)  # prints: {'l', 'o', 'H', 'e'}
print(letters1 == letters2)  # prints: True
```

请注意，对于集合理解，与字典一样，不允许重复，因此生成的集合只有四个字母。另外，请注意，指定给`letters1`和`letters2`的表达式会生成等价的集合。

用于创建`letters2`的语法与我们可以用于创建字典的语法非常相似。只有字典需要用列分隔的键和值，而集合不需要，您才能发现差异。

# 发电机

**生成器**是 Python 提供给我们的一个非常强大的工具。正如我们前面所说，它们基于*迭代*的概念，并且允许将优雅与效率结合在一起的编码模式。

发电机有两种类型：

*   **生成器函数**：这些函数与常规函数非常相似，但它们不是通过返回语句返回结果，而是使用收益率，这允许它们在每次调用之间暂停并恢复状态
*   **生成器表达式**：这些与我们在本章中看到的列表理解非常相似，但它们不是返回列表，而是返回一个对象，该对象会逐个生成结果

## 发电机功能

**生成器函数**在所有方面都与常规函数类似，但有一个区别：它们不需要收集结果并立即返回，而是可以开始计算，生成一个值，暂停其状态，保存需要恢复的所有内容，如果再次调用，则恢复并执行另一个步骤。Python 会自动将生成器函数转换为自己的迭代器，因此您可以对它们调用`next`。

这都是非常理论化的，让我们弄清楚为什么这样一个机制如此强大，然后让我们看一个例子。

比如说我让你大声数到一百万。你开始，在某个时刻我要求你停止。过了一段时间，我请你继续。此时，要正确恢复，您需要的最低信息是什么？嗯，你需要记住你打电话的最后一个号码。如果我在 31415 之后阻止你，你只会继续 31416，以此类推。

关键是，你不需要记住你在 31415 之前说过的所有数字，也不需要把它们写在什么地方。嗯，你可能不知道，但你已经表现得像个发电机了！

请仔细查看以下代码：

`first.n.squares.py`

```
def get_squares(n):  # classic function approach
    return [x ** 2 for x in range(n)]
print(get_squares(10))

def get_squares_gen(n):  # generator approach
    for x in range(n):
        yield x ** 2  # we yield, we don't return
print(list(get_squares_gen(10)))
```

打印结果将相同：`[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]`。但这两种功能之间存在巨大差异。`get_squares`是一个经典函数，它收集列表中【0，*n*中的所有数字平方并返回。另一方面，`get_squares_gen`是一个生成器，其行为非常不同。每次解释器到达`yield`时行，它的执行被暂停。这些打印返回相同结果的唯一原因是我们将`get_squares_gen`馈送给`list`构造函数，当这样调用时，它通过询问下一个元素直到`StopIteration`被激发，从而完全耗尽生成器。让我们详细看一下：

`first.n.squares.manual.py`

```
def get_squares_gen(n):
    for x in range(n):
        yield x ** 2

squares = get_squares_gen(4)  # this creates a generator object
print(squares)  # <generator object get_squares_gen at 0x7f158...>
print(next(squares))  # prints: 0
print(next(squares))  # prints: 1
print(next(squares))  # prints: 4
print(next(squares))  # prints: 9
# the following raises StopIteration, the generator is exhausted,
# any further call to next will keep raising StopIteration
print(next(squares))
```

在前面的代码中，每次调用 generator 对象上的`next`时，我们要么启动它（首先是`next`），要么让它从最后一个暂停点（任何其他`next`）恢复。

第一次调用`next`时，我们得到`0`，它是`0`的平方，然后是`1`，然后是`4`，然后是`9`，由于`for`回路在此之后停止（`n`是`4`，发电机自然结束。经典函数此时只返回`None`，但为了遵守迭代协议，生成器将引发`StopIteration`异常。

这个解释了`for`循环是如何工作的。当你调用`for k in range(n)`时，`for`循环从`range(n)`中得到一个迭代器，并开始调用`next`，直到`StopIteration`被触发，这告诉`for`循环迭代已经结束。

在 Python 的每个迭代方面都内置了这种行为，这使得生成器更加强大，因为一旦我们编写了生成器，我们就能够将它们插入到我们想要的任何迭代机制中。

此时，您可能会问自己为什么要使用生成器而不是常规函数。好吧，这一章的标题应该能给出答案。稍后我将讨论性能，所以现在让我们专注于另一个方面：有时生成器允许您执行一些简单列表无法实现的操作。例如，假设要分析序列的所有排列。如果序列长度为*N*，则其置换数为*N！*。这意味着，如果序列长度为 10 个元素，则排列数为 3628800。但是一个由 20 个元素组成的序列将有 2432902008176640000 个排列。它们成倍增长。

现在假设您有一个经典函数，它试图计算所有排列，将它们放入列表中，然后返回给您。对于 10 个元素，可能需要几十秒，但对于 20 个元素，根本无法完成。

另一方面，生成函数将能够开始计算并返回第一个置换，然后是第二个置换，依此类推。当然，你没有时间去解析它们，它们太多了，但至少你可以处理其中的一些。

还记得我们在`for`循环中讨论`break`语句的时候吗？当我们发现一个数字除以一个*候选素数*时，我们打破了循环，不需要继续。

有时情况完全一样，只是需要迭代的数据量太大，以至于无法将所有数据都保存在列表的内存中。在这种情况下，发电机是无价的：它们使原本不可能的事情成为可能。

因此，为了节省内存（和时间），尽可能使用生成器功能。

还值得注意的是，您可以在生成器函数中使用 return 语句。它将产生一个要引发的`StopIteration`异常，从而有效地结束迭代。这是非常重要的。如果一个`return`语句实际上要使函数返回一些东西，它将破坏迭代协议。Python 的一致性防止了这种情况，并使我们在编码时非常容易。让我们看一个简单的例子：

`gen.yield.return.py`

```
def geometric_progression(a, q):
    k = 0
    while True:
        result = a * q**k
        if result <= 100000:
            yield result
        else:
            return
        k += 1

for n in geometric_progression(2, 5):
    print(n)
```

前面的代码生成了几何级数*a*、*aq*、![Generator functions](images/4715_05_01.jpg)、![Generator functions](images/4715_05_02.jpg)的所有项。。。。当级数产生大于 100000 的项时，生成器停止（使用`return`语句）。运行代码会产生以下结果：

```
$ python gen.yield.return.py
2
10
50
250
1250
6250
31250

```

下一个学期将是 156250，这太大了。

## 超越下一步

在本章的开头，我告诉过您生成器对象是基于迭代协议的。我们将在下一章中看到如何编写自定义迭代器/iterable 对象的完整示例。现在，我只想让你们了解`next()`是如何工作的。

当您调用`next(generator)`时，会发生的情况是您正在调用`generator.__next__()`方法。记住，**方法**只是属于对象的函数，Python 中的对象可以有特殊的方法。我们的朋友`__next__()`只是其中之一，它的目的是返回迭代的下一个元素，或者在迭代结束且没有更多元素可返回时提出`StopIteration`。

### 注

在Python 中，对象的特殊方法也称为**魔术方法**或**邓德**（来自“双下划线”）**方法**。

当我们编写一个生成器函数时，Python 会自动将其转换为一个非常类似于迭代器的对象，当我们调用`next(generator)`时，该调用会在`generator.__next__()`中转换。让我们重温上一个关于生成正方形的示例：

`first.n.squares.manual.method.py`

```
def get_squares_gen(n):
    for x in range(n):
        yield x ** 2

squares = get_squares_gen(3)
print(squares.__next__())  # prints: 0
print(squares.__next__())  # prints: 1
print(squares.__next__())  # prints: 4
# the following raises StopIteration, the generator is exhausted,
# any further call to next will keep raising StopIteration
print(squares.__next__())
```

结果与前面的示例完全相同，只是这次没有使用代理调用`next(squares)`，而是直接调用`squares.__next__()`。

生成器对象还有其他三种方法可以控制其行为：`send`、`throw`和`close`。`send`允许我们将值传回生成器对象，而`throw`和`close`分别允许在生成器内引发异常并将其关闭。它们的使用非常先进，我不会在这里详细介绍它们，但我想用一个简单的例子来介绍一下`send`。

请看下面的代码：

`gen.send.preparation.py`

```
def counter(start=0):
    n = start
    while True:
        yield n
        n += 1

c = counter()
print(next(c))  # prints: 0
print(next(c))  # prints: 1
print(next(c))  # prints: 2
```

前面的迭代器创建一个将永远运行的生成器对象。你可以继续呼唤它，它永远不会停止。或者，你可以把它放在一个`for`循环中，例如`for n in counter(): ...`，它也将永远持续下去。

现在，如果你想在某个时候阻止它呢？一种解决方案是使用一个变量来控制`while`循环。大概是这样的：

`gen.send.preparation.stop.py`

```
stop = False
def counter(start=0):
    n = start
    while not stop:
        yield n
        n += 1

c = counter()
print(next(c))  # prints: 0
print(next(c))  # prints: 1
stop = True
print(next(c))  # raises StopIteration
```

这就行了。我们从`stop = False`开始，直到我们将其更改为`True`，发电机将继续运行，就像以前一样。但当我们将 stop 更改为`True`时，`while`循环将退出，下一次调用将引发`StopIteration`异常。这个把戏管用，但我不喜欢。我们依赖于一个外部变量，这可能会导致问题：如果另一个函数改变了`stop`，该怎么办？此外，代码是分散的。简而言之，这还不够好。

我们可以使用`generator.send()`使其更好。当我们调用`generator.send()`时，我们提供给`send`的值将传递给生成器，执行将继续，我们可以通过`yield`表达式获取它。当用文字解释时，这一切都非常复杂，所以让我们看一个例子：

`gen.send.py`

```
def counter(start=0):
    n = start
    while True:
        result = yield n             # A
        print(type(result), result)  # B
        if result == 'Q':
 break
        n += 1

c = counter()
print(next(c))         # C
print(c.send('Wow!'))  # D
print(next(c))         # E
print(c.send('Q'))     # F
```

执行上述代码会产生以下结果：

```
$ python gen.send.py
0
<class 'str'> Wow!
1
<class 'NoneType'> None
2
<class 'str'> Q
Traceback (most recent call last):
 File "gen.send.py", line 14, in <module>
 print(c.send('Q'))     # F
StopIteration

```

我认为应该逐行检查这段代码，就像我们在执行它一样，看看我们是否能理解发生了什么。

我们通过调用`next`（`#C`来启动生成器执行。在发电机内，`n`设置为与`start`相同的值。进入`while`循环，执行停止（`#A`），并将`n`（0）返回给调用者。0 打印在控制台上。

然后我们调用`send`（`#D`），继续执行，将`result`设置为`'Wow!'`（仍然是`#A`），然后在控制台上打印其类型和值（`#B`。`result`不是`'Q'`，因此`n`增加 1，执行返回`while`条件，即`True`，计算结果为`True`（这不难猜测，对吧？）。另一个循环循环开始，执行再次停止（`#A`），并且`n`（1）返回给调用方。1 打印在控制台上。

此时，我们调用`next`（`#E`），再次恢复执行（`#A`），因为我们没有显式地向生成器发送任何内容，Python 的行为与不使用`return`语句的函数完全相同：`yield n`表达式（`#A`返回`None`。因此将`result`设置为`None`，其类型和值再次打印在控制台上（`#B`。执行继续，`result`不是`'Q'`，所以`n`增加 1，我们再次开始另一个循环。再次停止执行（`#A`），并将`n`（2）返回给调用方。2 打印在控制台上。

现在是大结局：我们再次调用`send`（`#F`，但这次我们传入`'Q'`，因此当执行恢复时，`result`被设置为`'Q'`（`#A`。在控制台（`#B`上打印其类型和值，`if`子句最后计算为`True`，并且`while`循环被`break`语句停止。生成器自然终止，这意味着引发`StopIteration`异常。您可以在控制台上打印的最后几行上看到它的回溯打印。

这一点一开始并不容易理解，所以如果你不清楚，不要气馁。您可以继续阅读，过一段时间后再回到这个示例。

使用`send`允许使用有趣的模式，值得注意的是`send`只能用于恢复执行，不能用于启动执行。只有`next`开始执行生成器。

## 表达的产量

另一个有趣的结构是`yield from`表达式。此表达式允许您从子迭代器生成值。它的使用允许非常高级的模式，所以让我们来看一个非常快速的例子：

`gen.yield.for.py`

```
def print_squares(start, end):
    for n in range(start, end):
 yield n ** 2

for n in print_squares(2, 5):
    print(n)
```

前面的代码在控制台上打印数字`4`、`9`、`16`（在单独的行上）。现在，我希望您能够自己理解它，但让我们快速回顾一下发生了什么。函数外部的`for`循环从`print_squares(2, 5)`获取一个迭代器，并对其调用`next`，直到迭代结束。每次调用生成器时，`yield n ** 2`上的执行都会暂停（随后恢复），返回当前`n`的平方。

让我们看看如何从`yield from`表达式中转换此代码：

`gen.yield.from.py`

```
def print_squares(start, end):
    yield from (n ** 2 for n in range(start, end))

for n in print_squares(2, 5):
    print(n)
```

这段代码产生相同的结果，但正如您所看到的，`yield from`实际上正在运行子迭代器`(n ** 2 …)`。`yield from`表达式将子迭代器生成的每个值返回给调用方。它更短，而且读起来更好。

## 生成器表达式

现在我们来讨论一下一次生成一个值的其他技术。

语法与列表理解完全相同，只是没有将理解用方括号括起来，而是用圆括号括起来。这被称为**生成器表达式**。

一般来说，生成器表达式的行为类似于等价的列表理解，但有一件非常重要的事情需要记住：生成器只允许一次迭代，然后它们将被耗尽。让我们看一个例子：

`generator.expressions.py`

```
>>> cubes = [k**3 for k in range(10)]  # regular list
>>> cubes
[0, 1, 8, 27, 64, 125, 216, 343, 512, 729]
>>> type(cubes)
<class 'list'>
>>> cubes_gen = (k**3 for k in range(10))  # create as generator
>>> cubes_gen
<generator object <genexpr> at 0x7ff26b5db990>
>>> type(cubes_gen)
<class 'generator'>
>>> list(cubes_gen)  # this will exhaust the generator
[0, 1, 8, 27, 64, 125, 216, 343, 512, 729]
>>> list(cubes_gen)  # nothing more to give
[]

```

查看创建生成器表达式并指定名称`cubes_gen`的行。您可以看到它是一个生成器对象。为了查看它的元素，我们可以使用一个`for`循环，一组对`next`的手动调用，或者简单地将它提供给`list`构造函数，这就是我所做的。

请注意，一旦生成器耗尽，就无法再次从中恢复相同的元素。如果我们想从头开始使用它，我们需要重新创建它。

在接下来的几个示例中，让我们看看如何使用生成器表达式重现`map`和`filter`：

`gen.map.py`

```
def adder(*n):
    return sum(n)
s1 = sum(map(lambda n: adder(*n), zip(range(100), range(1, 101))))
s2 = sum(adder(*n) for n in zip(range(100), range(1, 101)))
```

在前面的示例中，`s1`和`s2`完全相同：它们是`adder(0, 1), adder(1, 2), adder(2, 3)`的和，依此类推，翻译成`sum(1, 3, 5, ...)`。虽然语法不同，但我发现生成器表达式更具可读性：

`gen.filter.py`

```
cubes = [x**3 for x in range(10)]
odd_cubes1 = filter(lambda cube: cube % 2, cubes)
odd_cubes2 = (cube for cube in cubes if cube % 2)
```

在前面的示例中，`odd_cubes1`和`odd_cubes2`是相同的：它们生成奇数立方体的序列。同样，我更喜欢生成器语法。当事情变得更复杂时，这一点应该是显而易见的：

`gen.map.filter.py`

```
N = 20
cubes1 = map(
    lambda n: (n, n**3),
    filter(lambda n: n % 3 == 0 or n % 5 == 0, range(N))
)
cubes2 = (
    (n, n**3) for n in range(N) if n % 3 == 0 or n % 5 == 0)
```

前面的代码创建到生成器`cubes1`和`cubes2`。它们完全相同，当*n*是 3 或 5 的倍数时，返回 2 元组（*n*、![Generator expressions](images/4715_05_04.jpg)）。

如果您打印列表（`cubes1`，您将得到：`[(0, 0), (3, 27), (5, 125), (6, 216), (9, 729), (10, 1000), (12, 1728), (15, 3375), (18, 5832)]`。

查看生成器表达式的读取效果有多好？当事情非常简单时，这可能是有争议的，但只要您开始嵌套函数一点，就像我们在本例中所做的那样，生成器语法的优越性就显而易见了。更短、更简单、更优雅。

现在，让我问你一个问题：以下代码行之间的区别是什么？

`sum.example.py`

```
s1 = sum([n**2 for n in range(10**6)])
s2 = sum((n**2 for n in range(10**6)))
s3 = sum(n**2 for n in range(10**6))
```

严格地说，它们产生的总数是一样的。因为`s2`中的大括号是冗余的，所以得到`s2`和`s3`的表达式完全相同。它们都是`sum`函数中的生成器表达式。然而，得到`s1`的表达式是不同的。在`sum`中，我们找到了一个列表。这意味着为了计算`s1`，`sum`函数必须在列表上调用`next`一百万次。

你看到我们失去时间和记忆的地方了吗？在`sum`可以开始调用该列表上的`next`之前，该列表需要已经创建，这是浪费时间和空间的。`sum`调用`next`一个简单的生成器表达式要好得多。不需要将`range(10**6)`中的所有数字存储在列表中。

所以，*在编写表达式*时要注意额外的括号：有时很容易忽略这些细节，这使得我们的代码大不相同。不相信我？

`sum.example.2.py`

```
s = sum([n**2 for n in range(10**8)])  # this is killed
# s = sum(n**2 for n in range(10**8))  # this succeeds
print(s)
```

尝试运行前面的示例。如果我运行第一行，我得到的是：

```
$ python sum.example.2.py
Killed

```

另一方面，如果我注释掉第一行，并取消注释第二行，则结果如下：

```
$ python sum.example.2.py
333333328333333350000000

```

甜生成器表达式。这两行的区别在于，在第一行中，必须先列出前一亿个数字的平方，然后才能将它们相加。这个列表是巨大的，而且我们的内存用完了（至少，我的盒子用完了，如果你不尝试更大的数字的话），因此 Python 为我们扼杀了这个进程。悲伤的脸。

但是当我们去掉方括号时，我们就不再列出清单了。sum 函数接收 0、1、4、9 等等，直到最后一个，然后将它们相加。没问题，笑脸。

# 一些性能注意事项

所以，我们已经看到，我们有许多不同的方法来实现相同的结果。我们可以使用`map`、`zip`、`filter`的任意组合，或者选择理解，或者选择使用生成器，函数或表达式。我们甚至可能决定使用`for`循环：当应用于每个运行参数的逻辑不简单时，它们可能是最佳选择。

除了可读性问题之外，让我们谈谈性能。说到表演，通常有两个因素起主要作用：**空间**和**时间**。

空间是指数据结构将占用的内存大小。最好的选择方法是问问自己是否真的需要一个列表（或元组），或者一个简单的生成器函数是否也可以工作。如果答案是肯定的，那就用发电机吧，它会节省很多空间。函数也是如此：如果您实际上不需要它们返回列表或元组，那么您也可以在生成器函数中转换它们。

有时，您必须使用列表（或元组），例如，有一些算法使用多个指针扫描序列，或者可能会在序列上运行多次。生成器函数（或表达式）只能迭代一次，然后就会耗尽，因此在这些情况下，它不是正确的选择。

时间比空间难一点，因为它依赖于更多的变量，因此不可能在所有情况下都绝对肯定地说*X 比 Y*快。然而，根据今天在 Python 上运行的测试，我们可以说`map`调用的速度是等效`for`循环的两倍，列表理解（通常来说）甚至比等效`map`调用更快。

为了充分理解这些语句背后的原因，我们需要了解 Python 是如何工作的，这有点超出了本书的范围，因为它在细节上太过技术化。让我们假设`map`和`list`理解在解释器中以 C 语言速度运行，而 Python`for`循环在 Python 虚拟机中作为 Python 字节码运行，这通常要慢得多。

### 注

Python 有几种不同的实现。最初的，也是最常见的一种，是用 C 语言编写的。C 语言是至今仍在使用的最强大和最流行的编程语言之一。

我所说的这些话来自于你可以在网上找到的书籍和文章，但是我们做一个小练习，试着自己去发现，怎么样？我将编写一小段代码，收集某组整数对`(a, b)`的`divmod(a, b)`结果。我将使用`time`模块中的`time`功能来计算我将执行的操作的运行时间。走吧！

`performances.py`

```
from time import time
mx = 5500  # this is the max I could reach with my computer...

t = time()  # start time for the for loop
dmloop = []
for a in range(1, mx):
    for b in range(a, mx):
        dmloop.append(divmod(a, b))
print('for loop: {:.4f} s'.format(time() - t))  # elapsed time

t = time()  # start time for the list comprehension
dmlist = [
    divmod(a, b) for a in range(1, mx) for b in range(a, mx)]
print('list comprehension: {:.4f} s'.format(time() - t))

t = time()  # start time for the generator expression
dmgen = list(
    divmod(a, b) for a in range(1, mx) for b in range(a, mx))
print('generator expression: {:.4f} s'.format(time() - t))

# verify correctness of results and number of items in each list
print(dmloop == dmlist == dmgen, len(dmloop))
```

如您所见，我们正在创建三个列表：`dmloop`、`dmlist`、`dmgen`（`divmod`-`for`循环、`divmod`-`list`理解、`divmod`-生成器表达式）。我们从最慢的选项开始，`for`循环。然后我们有一个`list`理解，最后是一个生成器表达式。让我们看看输出：

```
$ python performances.py
for loop: 4.3433 s
list comprehension: 2.7238 s
generator expression: 3.1380 s
True 15122250

```

`list`理解占用`for`循环 63%的时间。真令人印象深刻。生成器表达式与此非常接近，有很好的 72%。生成器表达式速度较慢的原因是我们需要将其提供给`list()`构造函数，与纯粹的列表理解相比，这会增加一点开销。

在类似的情况下，我永远不会使用生成器表达式，但是，如果最后我们想要一个列表，那就没有意义了。我将使用列表理解，上一个示例的结果证明我是正确的。另一方面，如果我必须在不保留结果的情况下进行这些`divmod`计算，那么生成器表达式将是一种可行的方法，因为在这种情况下，列表理解将不必要地消耗大量空间。

总而言之，发电机速度非常快，可以节省空间。列表理解通常更快，但不会节省空间。纯 Python`for`循环是最慢的选项。让我们看一个比较`for`循环和`map`调用的类似示例：

`performances.map.py`

```
from time import time
mx = 2 * 10 ** 7

t = time()
absloop = []
for n in range(mx):
    absloop.append(abs(n))
print('for loop: {:.4f} s'.format(time() - t))

t = time()
abslist = [abs(n) for n in range(mx)]
print('list comprehension: {:.4f} s'.format(time() - t))

t = time()
absmap = list(map(abs, range(mx)))
print('map: {:.4f} s'.format(time() - t))

print(absloop == abslist == absmap)
```

此代码在概念上与前面的示例非常相似。唯一改变的是我们正在应用`abs`函数而不是`divmod`函数，并且我们只有一个循环而不是两个嵌套的循环。执行会产生以下结果：

```
$ python performances.map.py
for loop: 3.1283 s
list comprehension: 1.3966 s
map: 1.2319 s
True

```

而且`map`赢得了比赛！正如我之前告诉过你的，给出一个关于什么比什么更快的陈述是非常棘手的。在这种情况下，`map`调用比列表理解更快。

除了个别情况的细微差异外，`for`循环选项显然是最慢的选项，所以让我们看看我们仍然希望使用它的原因是什么。

# 不要过度理解和理解

我们已经看到了列表理解和生成器表达式的强大功能。它们是，别误会，但我在处理它们时的感觉是它们的复杂性呈指数级增长。你在一个理解或一个生成表达式中做的越多，它就越难阅读、理解，因此也就越难保持或改变。

打开 Python 控制台，输入`import this`，让我们再次阅读 Python 的禅宗，特别是有几行我认为非常重要的内容需要记住：

```
>>> import this
The Zen of Python, by Tim Peters

Beautiful is better than ugly.
Explicit is better than implicit.  #
Simple is better than complex.  #
Complex is better than complicated.
Flat is better than nested.
Sparse is better than dense.
Readability counts.  #
Special cases aren't special enough to break the rules.
Although practicality beats purity.
Errors should never pass silently.
Unless explicitly silenced.
In the face of ambiguity, refuse the temptation to guess.
There should be one-- and preferably only one --obvious way to do it.
Although that way may not be obvious at first unless you're Dutch.
Now is better than never.
Although never is often better than *right* now.
If the implementation is hard to explain, it's a bad idea.  #
If the implementation is easy to explain, it may be a good idea.
Namespaces are one honking great idea -- let's do more of those!

```

我已经在这里的主要焦点的右边放了一个评论标志。理解和生成器表达式变得难以阅读，比显式更含蓄，更复杂，也很难解释。有时，你必须使用由内而外的技术将它们分开，以了解它们产生结果的原因。

举个例子，让我们再多谈一点勾股三元组。提醒一下，毕达哥拉斯三元组是一个正整数的元组（*a*、*b*、*c*），因此![Don't overdo comprehensions and generators](images/4715_05_05.jpg)。

我们在本章前面看到了如何计算它们，但是我们做得非常低效，因为我们扫描了低于某个阈值的所有数字对，计算斜边，过滤掉那些没有产生三元组的数字。

获取毕达哥拉斯三元组列表的更好方法是直接生成它们。有许多不同的公式可以做到这一点，我们将使用其中一个：**欧几里德公式**。

这个公式表示任何三元组（*a*、*b*、*c*），其中![Don't overdo comprehensions and generators](images/4715_05_06.jpg)、*b=2mn*、![Don't overdo comprehensions and generators](images/4715_05_07.jpg)、具有*m*和*n*正整数的*m>n*是毕达哥拉斯三元组。例如，当*m=2*和*n=1*时，我们找到最小的三元组：（3，4，5）。

有一个捕捉：考虑三（6, 8, 10），这就像（3, 4, 5），所有的数字乘以 2。这个三元组绝对是毕达哥拉斯式的，因为![Don't overdo comprehensions and generators](images/4715_05_08.jpg)，但我们可以通过将其每个元素乘以*2*简单地从（3，4，5）推导出它。（9，12，15），（12，16，20）也是如此，一般来说，我们可以写为（3k，4k，5k）的所有三元组，*k*是大于 1 的正整数。

一个三元组不能通过将另一个三元组的元素乘以某个因子*k*来获得，它被称为**本原**。另一种说法是：如果三元组的三个元素是**互质**，那么三元组就是本原。当两个数的除数之间不共享任何素数因子时，它们是互质的，即它们的**最大公约数**（**GCD**为 1。例如，3 和 5 是互质，而 3 和 6 不是互质，因为它们都可以被 3 整除。

因此，欧几里德公式告诉我们，如果*m*和*n*是互质，并且*m–n*是奇数，那么它们生成的三元组就是*本原*。在下面的示例中，我们将编写一个生成器表达式来计算斜边（*c*）小于或等于某个整数*N*的所有原始毕达哥拉斯三元组。这意味着我们需要![Don't overdo comprehensions and generators](images/4715_05_09.jpg)的所有三元组。当*n*为*1*时，公式如下：![Don't overdo comprehensions and generators](images/4715_05_10.jpg)，这意味着我们可以用![Don't overdo comprehensions and generators](images/4715_05_11.jpg)的上限来近似计算。

所以，概括一下：*m*必须大于*n*，它们也必须是互质，它们的差*m-n*必须是奇数。此外，为了避免无用的计算，我们将*m*的上限置于*层（sqrt（N））+1*。

### 注

实数*x*的函数`floor`给出最大整数*n*，使得*n<x*，例如*层（3.8）=3*、*层（13.1）=13*。取*层（sqrt（N））+1*意味着取*N*平方根的整数部分，并添加最小余量，以确保我们不会遗漏任何数字。

让我们一步一步地把这些都写进代码中。让我们从开始编写一个使用**欧几里德算法**的简单`gcd`函数：

`functions.py`

```
def gcd(a, b):
    """Calculate the Greatest Common Divisor of (a, b). """
    while b != 0:
        a, b = b, a % b
    return a
```

关于欧几里德算法的解释可以在网络上找到，所以我不会在这里花时间讨论它；我们需要专注于生成器表达式。下一步是使用我们之前收集的知识生成原始毕达哥拉斯三元组列表：

`pythagorean.triple.generation.py`

```
from functions import gcd
N = 50

triples = sorted(                                      # 1
    ((a, b, c) for a, b, c in (                        # 2
        ((m**2 - n**2), (2 * m * n), (m**2 + n**2))    # 3
        for m in range(1, int(N**.5) + 1)              # 4
        for n in range(1, m)                           # 5
        if (m - n) % 2 and gcd(m, n) == 1              # 6
    ) if c <= N), key=lambda *triple: sum(*triple)     # 7
)

print(triples)
```

好了。这不容易读，所以让我们一行一行地看一遍。在`#3`处，我们启动一个正在创建三元组的生成器表达式。从`#4`和`#5`可以看出，我们在*【1，M】*中循环`m`，其中*M*是*sqrt（N）*的整数部分，加上 1。另一方面，*【1，m】*中的`n`循环，以尊重*m>n*规则。值得注意的是，我是如何计算*sqrt（n）*，即`N**.5`，这只是我想展示给大家的另一种方法。

在`#6`中，您可以看到使三元组原语的过滤条件：`(m - n)`为奇数时`(m - n) % 2`计算为`True`，且`gcd(m, n) == 1`表示`m`和`n`为互质。有了这些，我们知道三元组将是原始的。这将处理最内部的生成器表达式。最外面的一个从`#2`开始，在`#7`结束。我们将三元组（*a*、*b*、*c*放入（……最里面的生成器…）中，以便`c <= N`。这是必要的，因为![Don't overdo comprehensions and generators](images/4715_05_11.jpg)是我们可以应用的最低上限，但它不能保证*c*实际上会小于或等于*N*。

最后，在`#1`我们应用排序，以按顺序呈现列表。在`#7`处，当最外层的生成器表达式关闭后，您可以看到我们将排序键指定为*a+b+c*之和。这只是我个人的喜好，没有数学上的原因。

那么，你认为呢？读起来容易吗？我不这么认为。相信我，这仍然是一个简单的例子；我见过比这更复杂的表达方式。

不幸的是，一些程序员认为编写这样的代码很酷，这是他们卓越智力的某种展示，是他们快速阅读和消化复杂代码的能力的展示。

然而，在一个专业的环境中，我发现自己更尊重那些编写高效、干净的代码并设法将自我拒之门外的人。相反地，那些不这样做的人，会在用三种语言咒骂的时候，产生你会盯着看很长时间的台词（至少我是这样做的）。

现在，让我们看看是否可以将此代码重写为更易于阅读的内容：

`pythagorean.triple.generation.for.py`

```
from functions import gcd

def gen_triples(N):
    for m in range(1, int(N**.5) + 1):            # 1
        for n in range(1, m):                     # 2
            if (m - n) % 2 and gcd(m, n) == 1:    # 3
                c = m**2 + n**2                   # 4
                if c <= N:                        # 5
                    a = m**2 - n**2               # 6
                    b = 2 * m * n                 # 7
                    yield (a, b, c)               # 8

triples = sorted(
    gen_triples(50), key=lambda *triple: sum(*triple))  # 9
print(triples)
```

我已经感觉好多了。让我们一行一行地检查一下这段代码。你会发现这是多么容易理解。

我们从`#1`和`#2`开始循环，与前面示例中的循环方式完全相同。在第`#3`行，我们对原始三元组进行了过滤。在`#4`线上，我们与之前做的有些不同：我们计算`c`，在`#5`线上，我们过滤`c`小于或等于`N`。只有当`c`满足该条件时，我们才计算`a`和`b`，并生成结果元组。尽可能多地延迟所有计算总是好的，这样我们就不会浪费时间，以防最终我们不得不放弃这些结果。

在最后一行，在打印结果之前，我们使用生成器表达式示例中使用的相同键应用排序。

我希望你同意，这个例子更容易理解。我向你保证，如果有一天你不得不修改代码，你会发现修改这个代码很容易，而修改另一个版本则需要更长的时间（而且更容易出错）。

运行这两个示例时，请打印以下内容：

```
$ python pythagorean.triple.generation.py
[(3, 4, 5), (5, 12, 13), (15, 8, 17), (7, 24, 25), (21, 20, 29), (35, 12, 37), (9, 40, 41)]

```

这个故事的寓意是，尽可能多地尝试使用理解和生成器表达式，但如果代码开始变得复杂而难以修改或阅读，您可能希望重构为更具可读性的代码。这没什么错。

# 名称本地化

既然我们已经熟悉了所有类型的理解和生成器表达式，那么让我们来谈谈其中的名称本地化。Python 3.*在所有四种理解形式中本地化循环变量：`list`、`dict`、`set`和生成器表达式。因此，该行为与`for`循环不同。让我们看一个简单的例子来说明所有情况：

`scopes.py`

```
A = 100
ex1 = [A for A in range(5)]
print(A)  # prints: 100

ex2 = list(A for A in range(5))
print(A)  # prints: 100

ex3 = dict((A, 2 * A) for A in range(5))
print(A)  # prints: 100

ex4 = set(A for A in range(5))
print(A)  # prints: 100

s = 0
for A in range(5):
    s += A
print(A)  # prints: 4
```

在前面的代码中，我们声明了一个全局名称`A = 100`，然后我们练习了四种理解：list、generator 表达式、dictionary 和 set。它们都没有更改全局名称`A`。相反，您可以在结尾看到`for`循环修改了它。最后一个 print 语句打印 4。

让我们看看如果`A`不在那里会发生什么：

`scopes.noglobal.py`

```
ex1 = [A for A in range(5)]
print(A)  # breaks: NameError: name 'A' is not defined
```

上述代码对四种理解中的任何一种都适用。在我们运行第一行之后，`A`没有在全局名称空间中定义。

`for`循环的行为再次不同：

`scopes.for.py`

```
s = 0
for A in range(5):
    s += A
print(A)  # prints: 4
print(globals())
```

前面的代码显示在`for`循环之后，如果循环变量之前没有定义，我们可以在全局框架中找到它。为了确保这一点，让我们通过调用 OutT1 内置函数来窥视它：

```
$ python scopes.for.py
4
{'__spec__': None, '__name__': '__main__', 's': 10, 'A': 4, '__doc__': None, '__cached__': None, '__package__': None, '__file__': 'scopes.for.py', '__loader__': <_frozen_importlib.SourceFileLoader object at 0x7f05a5a183c8>, '__builtins__': <module 'builtins' (built-in)>}

```

与许多其他样板资料一起，我们可以发现`'A': 4`。

# 内置的生成行为

在内置类型中，生成行为现在非常常见。这是 Python 2 和 Python 3 之间的一个主要区别。许多函数，如`map`、`zip`和`filter`都经过了转换，因此它们返回的对象的行为类似于 iterables。这一变化背后的想法是，如果你需要列出这些结果，你可以随时将调用包装在`list()`类中，这样你就完成了。另一方面，如果您只需要迭代并希望尽可能减少对内存的影响，那么您可以安全地使用这些函数。

另一个值得注意的例子是`range`函数。在 Python2 中，它返回一个列表，还有另一个名为`xrange`的函数，它返回一个可以迭代的对象，该对象会动态生成数字。在 Python3 中，这个函数已经消失了，`range`现在的行为与之类似。

但这一概念现在普遍存在。您可以在`open()`函数中找到它，该函数用于对文件对象进行操作（我们将在下面的一章中看到），也可以在`enumerate`、字典`keys`、`values`和`items`方法以及其他几个地方找到它。

这一切都是有道理的：Python 的目标是尽可能避免浪费空间，特别是在大多数情况下广泛使用的函数和方法中，从而尝试减少内存占用。

你还记得这一章的开头吗？我说过，优化处理大量对象的代码的性能比从我们每天调用两次的函数中节省几毫秒更有意义。

# 最后一个例子

在本章结束之前，我将向您展示一个简单的问题，我曾向一家公司的 Python 开发人员职位候选人提交过这个问题。

问题如下：给定序列`0 1 1 2 3 5 8 13 21 ...`编写一个函数，该函数将返回该序列的项，直至达到某个极限`N`。

如果你还没有认识到，那就是斐波那契序列，它被定义为*F（0）=0*、*F（1）=1*以及，对于任何*n>1*、*F（n）=F（n-1）+F（n-2）*。这个序列非常适合测试关于递归、记忆技术和其他技术细节的知识，但在本例中，这是一个很好的机会来检查应聘者是否知道生成器（当我采访他们时，有太多所谓的 Python 程序员不知道）。

让我们从函数的基本版本开始，然后对其进行改进：

`fibonacci.first.py`

```
def fibonacci(N):
    """Return all fibonacci numbers up to N. """
    result = [0]
    next_n = 1
    while next_n <= N:
        result.append(next_n)
        next_n = sum(result[-2:])
    return result

print(fibonacci(0))  # [0]
print(fibonacci(1))  # [0, 1, 1]
print(fibonacci(50))  # [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]
```

从顶部开始：我们将`result`列表设置为起始值`[0]`。然后我们从下一个元素（`next_n`）开始迭代，即`1`。虽然下一个元素不大于`N`，但我们会将其添加到列表中并计算下一个元素。我们通过从`result`列表中的最后两个元素中取一个切片并将其传递给`sum`函数来计算下一个元素。如果你不清楚的话，在这里或那里添加一些`print`声明，但现在我认为这不是一个问题。

当`while`循环的条件评估为`False`时，我们退出循环并返回`result`。您可以在每个`print`语句旁边的注释中看到这些语句的结果。

在这一点上，我会问应聘者以下问题：“如果我只想迭代这些数字呢？”一个好的应聘者会像下一个清单一样更改代码（一个优秀的应聘者会从它开始！）：

`fibonacci.second.py`

```
def fibonacci(N):
    """Return all fibonacci numbers up to N. """
    yield 0
    if N == 0:
        return
    a = 0
    b = 1
    while b <= N:
        yield b
        a, b = b, a + b

print(list(fibonacci(0)))  # [0]
print(list(fibonacci(1)))  # [0, 1, 1]
print(list(fibonacci(50))) # [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]
```

这实际上是我得到的解决方案之一。我不知道为什么我保留了它，但我很高兴我保留了它，这样我就可以给你看了。现在，`fibonacci`函数是*生成器函数*。首先我们产生`0`，然后如果`N`是`0`，我们返回（这将导致`StopIteration`异常被引发）。如果不是这样，我们开始迭代，在每个循环周期产生`b`，然后更新`a`和`b`。为了能够产生序列的下一个元素，我们所需要的只是过去的两个元素：`a`和`b`。

这个代码要好得多，内存占用更少，我们要得到一个斐波那契数列表所需要做的就是像往常一样用`list()`来包装调用。

但是优雅呢？我不能就这样离开代码。这对于一次面试来说是不错的，因为面试的重点更多的是功能而不是优雅，但在这里，我想向您展示一个更好的版本：

`fibonacci.elegant.py`

```
def fibonacci(N):
    """Return all fibonacci numbers up to N. """
    a, b = 0, 1
    while a <= N:
        yield a
        a, b = b, a + b
```

好多了。函数的整个主体是四行，如果计算 docstring，则为五行。请注意，在本例中，使用元组赋值（`a, b = 0, 1`和`a, b = b, a + b`有助于缩短代码，提高代码的可读性。这是 Python 的特性之一，我非常喜欢。

# 总结

在本章中，我们更深入地探讨了迭代和生成的概念。我们非常详细地了解了`map`、`zip`和`filter`函数，以及如何将它们用作常规`for`循环方法的替代方法。

然后我们看到了列表、词典和集合的理解概念。我们了解了它们的语法以及如何使用它们来替代经典的`for`循环方法以及`map`、`zip`和`filter`函数。

最后，我们讨论了生成的概念，有两种形式：生成函数和表达式。我们学习了如何通过使用生成技术来节省时间和空间，并了解了如果我们使用基于列表的传统方法，它们如何能够实现通常不会实现的功能。

我们讨论了性能，发现`for`循环在速度上是最后一个循环，但它们提供了最好的可读性和更改灵活性。另一方面，像`map`和`filter`这样的功能可以快得多，理解能力可能更好。

使用这些技术编写的代码的复杂性呈指数级增长，因此为了提高可读性和易维护性，我们有时仍然需要使用经典的`for`循环方法。另一个区别在于名称本地化，`for`循环的行为与所有其他类型的理解不同。

下一章将全部介绍对象和类。在结构上与此类似，我们不会探讨很多不同的主题，而只是其中的一小部分，但我们会尝试更深入一点。

在跳到下一章之前，请确保您充分理解本章的概念。我们正在建造一堵砖砌的墙，如果地基不牢固，我们不会走得很远。