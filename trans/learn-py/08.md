# 第九章。数据科学

|  | *“如果我们有数据，让我们看看数据。如果我们只有意见，让我们用我的观点。”* |  |
|  | --*吉姆·巴克斯代尔，前网景首席执行官* |

**数据科学**是一个非常宽泛的术语，可以根据上下文、理解、工具等假设几种不同的含义。关于这个主题的书数不胜数，不适合胆小的人。

为了做正确的数据科学，你至少需要知道数学和统计学。然后，你可能想深入研究其他学科，比如模式识别和机器学习，当然，你可以选择大量的语言和工具。

除非我在接下来的几分钟内转变成神奇的法布里齐奥，否则我无法谈论一切；我甚至不会接近它。因此，为了使这一章有意义，我们将一起做一个很酷的项目。

大约 3 年前，我在伦敦一家顶级社交媒体公司工作。我在那里呆了两年，有幸与几位才华横溢的人共事，我只能开始描述他们的才华。我们是世界上第一个访问 Twitter 广告 API 的人，我们也是 Facebook 的合作伙伴。这意味着大量的数据。

我们的分析师要处理大量的活动，他们要做的工作太多了，所以我所在的开发团队试图通过向他们介绍 Python 和 Python 提供的处理数据的工具来帮助他们。这是一次非常有趣的旅行，让我指导了该公司的几位员工，并最终来到马尼拉，在那里，我为那里的分析师提供了为期两周的 Python 和数据科学方面的强化培训。

在本章中，我们将一起做的项目是我向马尼拉学生介绍的最后一个示例的轻量级版本。我已经将它改写为适合本章的大小，并为教学目的做了一些调整，但所有的主要概念都在那里，所以编写代码对您来说应该是有趣和有指导意义的。

在我们的旅程中，我们将遇到一些在 Python 生态系统中可以找到的处理数据的工具，所以让我们从谈论罗马神开始。

# Ipyton 和 Jupyter 笔记本

2001 年，费尔南多·佩雷斯（FernandoPerez）是加拿大大学博尔德分校（CU Boulder）的一名物理学研究生，当时他正试图改进 Python 外壳，这样他就可以拥有一些细节，就像他在使用 Mathematica 和 Maple 等工具时所习惯的那样。这一努力的结果被命名为**伊皮顿**。

简而言之，这个小脚本最初是 pythonshell 的一个增强版本，通过其他程序员的努力，并最终从几个不同的公司获得适当的资金，它成为了今天的精彩和成功的项目。笔记本电脑诞生大约 10 年后，由 WebSockets、Tornado web 服务器、jQuery、CodeMirror 和 MathJax 等技术支持，创建了一个笔记本电脑环境。ZeroMQ 库还用于处理笔记本接口和其背后的 Python 核心之间的消息。

IPython 笔记本已经变得如此流行和广泛使用，最终，各种各样的好东西都被添加到了笔记本中。它可以处理小部件、并行计算、各种媒体格式等等。此外，在某种程度上，可以从笔记本中使用 Python 以外的语言编写代码。

这导致了一个巨大的项目，直到最近才被分成两部分：IPython 已经被剥离，更多地关注内核部分和外壳，而笔记本电脑已经成为一个名为**Jupyter**的全新项目。Jupyter 允许用 40 多种语言进行交互式科学计算。

本章的项目将全部编码并运行在 Jupyter 笔记本中，所以让我用几句话解释一下笔记本是什么。

笔记本环境是一个网页，它公开了一个简单的菜单和可以运行 Python 代码的单元格。尽管这些单元是可以单独运行的独立实体，但它们都共享相同的 Python 内核。这意味着您在一个单元格中定义的所有名称（变量、函数等）将在任何其他单元格中可用。

### 注

简单地说，Python 内核是运行 Python 的进程。因此，笔记本网页是一个向用户公开的界面，用于驱动此内核。网页使用非常快速的消息传递系统与之通信。

除了所有的图形优势外，拥有这样一个环境的好处在于能够分块运行 Python 脚本，这是一个巨大的优势。使用连接到数据库的脚本获取数据，然后操作该数据。如果您以传统的方式使用 Python 脚本进行操作，那么每次您想要使用它进行实验时，都必须获取数据。在笔记本环境中，您可以获取一个单元格中的数据，然后在其他单元格中对其进行操作和实验，因此无需每次都获取数据。

笔记本电脑环境对数据科学也非常有帮助，因为它允许一步一步地反省。你做一块工作，然后验证它。然后执行另一个块并再次验证，依此类推。

这对于原型设计也是非常宝贵的，因为结果就在眼前，可以立即获得。

如果您想了解更多关于这些工具的信息，请查看[http://ipython.org/](http://ipython.org/) 和[http://jupyter.org/](http://jupyter.org/) 。

我创建了一个非常简单的示例笔记本，它带有`fibonacci`函数，可以为您提供小于给定`N`的所有斐波那契数的列表。在我的浏览器中，它如下所示：

![IPython and Jupyter notebook](images/4715_09_01.jpg)

每个单元格都有一个**In[]**标签。如果大括号之间没有任何内容，则表示该单元格从未执行过。如果有一个数字，则表示该单元格已执行，该数字表示该单元格的执行顺序。最后，*****表示当前正在执行该单元。

您可以在图片中看到，在第一个单元格中，我定义了`fibonacci`函数，并且我已经执行了它。这具有将`fibonacci`名称放置在与笔记本相关联的全局框架中的效果，因此`fibonacci`功能现在也可用于其他单元格。事实上，在第二个单元格中，我可以运行`fibonacci(100)`并在**Out[2]**中看到结果。在第三个单元格中，我向您展示了在第二个单元格的笔记本中可以找到的几个神奇功能之一。**%timeit**多次运行代码，并为您提供了一个很好的基准测试。我在[第 5 章](04.html "Chapter 5\. Saving Time and Memory")*节省时间和内存*中对列表理解和生成器所做的所有测量都是使用这个漂亮的功能进行的。

您可以根据需要多次执行单元格，并更改运行它们的顺序。单元格具有很强的延展性，您还可以放入标记文本或将其呈现为标题。

### 注

**Markdown**是一种轻量级标记语言，设计了纯文本格式语法，可以将其转换为 HTML 和许多其他格式。

此外，您在单元格最后一行中放置的任何内容都将自动为您打印。这非常方便，因为您不必显式地编写`print(...)`。

自由探索笔记本电脑环境；一旦你和它成为朋友，这将是一段长久的关系，我保证。

为了运行笔记本电脑，你必须安装几个库，每个库都与其他库协作以使整个工作正常进行。或者，您可以只安装 Jupyter，它将为您处理一切。对于本章，我们还需要安装一些其他依赖项，因此请运行以下命令：

```py
$ pip install jupyter pandas matplotlib fake-factory delorean xlwt

```

别担心，我会逐步介绍给你的。现在，安装完这些库后（可能需要几分钟），您可以启动笔记本：

```py
$ jupyter notebook

```

这将在您的浏览器中打开以下地址的页面：`http://localhost:8888/`。

转到该页并使用菜单创建一个新笔记本。当你拥有它，并且你对它感到舒适时，我们就准备好出发了。

### 提示

如果您在设置笔记本环境时遇到任何问题，请不要气馁。如果您遇到错误，通常只需在 web 上搜索一点，您就会看到一个页面，其他人也有相同的问题，他们已经解释了如何解决。在继续本章之前，请尽最大努力启动并运行笔记本环境。

我们的项目将在笔记本中进行，因此我将在每个代码片段上标记它所属的单元号，以便您可以轻松地复制代码并跟进。

### 提示

如果您熟悉键盘快捷键（请参阅笔记本的“帮助”部分），您将能够在单元格之间移动并处理其内容，而无需触摸鼠标。当你在笔记本上工作时，这将使你更加熟练，速度更快。

# 数据处理

通常，当处理数据时，这是您所经历的路径：获取数据、清理和操作数据，然后检查数据并将结果显示为值、电子表格、图表等。我希望您能够在不依赖任何外部数据提供者的情况下负责流程的所有三个步骤，因此我们将执行以下操作：

1.  我们将创建数据，模拟这样一个事实，即数据的格式并不完美，也不适合处理。
2.  我们将对其进行清理，并将其提供给我们将在项目中使用的主要工具：`pandas`的**数据帧**。
3.  我们将操作数据框中的数据。
4.  我们将以不同的格式将数据帧保存到一个文件中。
5.  最后，我们将检查数据并从中得到一些结果。

## 设置笔记本

首先首先，我们需要设置笔记本。这意味着导入和一些配置。

`#1`

```py
import json
import calendar
import random
from datetime import date, timedelta

import faker
import numpy as np
from pandas import DataFrame
from delorean import parse
import pandas as pd

# make the graphs nicer
pd.set_option('display.mpl_style', 'default')
```

单元格`#1`负责进口。这里有很多新东西：`calendar`、`random`和`datetime`模块是标准库的一部分。他们的名字不言自明，让我们看看`faker`。`fake-factory`库为您提供了这个模块，您可以使用它来准备假数据。它在测试中非常有用，当你准备你的设备时，可以得到各种各样的信息，比如姓名、电子邮件地址、电话号码、信用卡详细信息等等。当然，这都是假的。

`numpy`是 NumPy 库，是使用 Python 进行科学计算的基本包。我将在本章后面的部分用几句话来说明这一点。

`pandas`是整个项目所基于的核心。代表**Python 数据分析库**。除此之外，它还提供了**数据帧**，一种具有高级处理能力的矩阵式数据结构。习惯上先单独导入`DataFrame`，然后再导入`import pandas as pd`。

`delorean`是一个不错的第三方库，可以显著加快处理日期。从技术上讲，我们可以使用标准库来实现，但我认为没有理由不扩展示例的范围，并向您展示一些不同的东西。

最后，我们在最后一行有一条指令，这将使最后的图形更漂亮一点，这并没有什么坏处。

## 准备数据

我们希望实现以下数据结构：我们将有一个用户对象列表。每个用户对象将链接到多个活动对象。

在 Python 中，一切都是一个对象，所以我以一种通用的方式使用这个术语。用户对象可以是字符串、dict 或其他对象。

社交媒体世界中的**活动**是媒体代理代表客户在社交媒体网络上开展的促销活动。

请记住，我们将准备这些数据，使其不是完美的形状（但也不会那么糟糕…）。

`#2`

```py
fake = faker.Faker()
```

首先，我们实例化将用于创建数据的`Faker`。

`#3`

```py
usernames = set()
usernames_no = 1000
# populate the set with 1000 unique usernames
while len(usernames) < usernames_no:
    usernames.add(fake.user_name())
```

然后我们需要用户名。我想要 1000 个唯一的用户名，所以我在`usernames`集合的长度上循环，直到它有 1000 个元素。集合不允许重复的元素，因此保证了唯一性。

`#4`

```py
def get_random_name_and_gender():
    skew = .6  # 60% of users will be female
    male = random.random() > skew
    if male:
        return fake.name_male(), 'M'
    else:
        return fake.name_female(), 'F'

def get_users(usernames):
    users = []
    for username in usernames:
        name, gender = get_random_name_and_gender()
        user = {
            'username': username,
            'name': name,
            'gender': gender,
            'email': fake.email(),
            'age': fake.random_int(min=18, max=90),
            'address': fake.address(),
        }
        users.append(json.dumps(user))
    return users

users = get_users(usernames)
users[:3]
```

在这里，我们创建一个用户列表。每一个`username`现在都被扩充为一个完整的`user`口述，还有其他细节，如姓名、性别、电子邮件等。然后将每个`user`dict 转储到 JSON 并添加到列表中。当然，这种数据结构不是最优的，但我们正在模拟一个场景，用户会像这样来找我们。

注意`random.random()`的使用偏颇，使得 60%的用户是女性。其余的逻辑应该很容易理解。

另请注意最后一行。每个单元格自动打印最后一行的内容；因此，这是一个包含前三个用户的列表：

`Out #4`

```py
['{"gender": "F", "age": 48, "email": "jovani.dickinson@gmail.com", "address": "2006 Sawayn Trail Apt. 207\\nHyattview, MO 27278", "username": "darcy00", "name": "Virgia Hilpert"}',
 '{"gender": "F", "age": 58, "email": "veum.javen@hotmail.com", "address": "5176 Andres Plains Apt. 040\\nLakinside, GA 92446", "username": "renner.virgie", "name": "Miss Clarabelle Kertzmann MD"}',
 '{"gender": "M", "age": 33, "email": "turner.felton@rippin.com", "address": "1218 Jacobson Fort\\nNorth Doctor, OK 04469", "username": "hettinger.alphonsus", "name": "Ludwig Prosacco"}']

```

### 注

我希望你是跟着你自己的笔记本。如果是，请注意，所有数据都是使用随机函数和值生成的；因此，您将看到不同的结果。每次执行笔记本时，它们都会更改。

`#5`

```py
# campaign name format:
# InternalType_StartDate_EndDate_TargetAge_TargetGender_Currency
def get_type():
    # just some gibberish internal codes
    types = ['AKX', 'BYU', 'GRZ', 'KTR']
    return random.choice(types)

def get_start_end_dates():
    duration = random.randint(1, 2 * 365)
    offset = random.randint(-365, 365)
    start = date.today() - timedelta(days=offset)
    end = start + timedelta(days=duration)

    def _format_date(date_):
        return date_.strftime("%Y%m%d")

    return _format_date(start), _format_date(end)

def get_age():
    age = random.randint(20, 45)
    age -= age % 5
    diff = random.randint(5, 25)
    diff -= diff % 5
    return '{}-{}'.format(age, age + diff)

def get_gender():
    return random.choice(('M', 'F', 'B'))

def get_currency():
    return random.choice(('GBP', 'EUR', 'USD'))

def get_campaign_name():
    separator = '_'
    type_ = get_type()
    start_end = separator.join(get_start_end_dates())
    age = get_age()
    gender = get_gender()
    currency = get_currency()
    return separator.join(
        (type_, start_end, age, gender, currency))
```

在`#5`中，我们定义了生成活动名称的逻辑。分析师们一直在使用电子表格，他们想出各种各样的编码技术，将尽可能多的信息压缩到活动名称中。我选择的格式是该技术的一个简单示例：有一个代码，告诉您活动类型，然后是开始和结束日期，然后是目标年龄和性别，最后是货币。所有值都用下划线分隔。

在`get_type`函数中，我使用`random.choice()`从集合中随机获取一个值。可能更有趣的是`get_start_end_dates`。首先，我得到活动的持续时间，从 1 天到 2 年（随机），然后我得到一个随机的时间偏移量，我从今天的日期中减去，以得到开始日期。假设偏移量是一个介于-365 和 365 之间的随机数，如果我将它添加到今天的日期而不是减去它，会有什么不同吗？

当我有开始日期和结束日期时，我返回它们的一个字符串化版本，并加上下划线。

然后，我们在年龄计算中有一些模块化的技巧。我希望您还记得[第 2 章](01.html "Chapter 2\. Built-in Data Types")*内置数据类型*中的模运算符（`%`。

这里发生的是，我想要一个日期范围，它的极端值是 5 的倍数。有很多方法可以做到这一点，但我要做的是得到一个 20 到 45 之间的随机数作为左端，然后把除法的剩余部分去掉 5。例如，如果我得到 28，我将删除*28%5=3*，得到 25。我本可以使用`random.randrange()`，但很难抵制模块化划分。

其余的函数只是`random.choice()`的一些其他应用程序，最后一个`get_campaign_name`只不过是所有这些拼图块的收集器，返回最终的活动名称。

`#6`

```py
def get_campaign_data():
    name = get_campaign_name()
    budget = random.randint(10**3, 10**6)
    spent = random.randint(10**2, budget)    
    clicks = int(random.triangular(10**2, 10**5, 0.2 * 10**5))    
    impressions = int(random.gauss(0.5 * 10**6, 2))
    return {
        'cmp_name': name,
        'cmp_bgt': budget,
        'cmp_spent': spent,
        'cmp_clicks': clicks,
        'cmp_impr': impressions
    }
```

在`#6`中，我们编写了一个创建完整活动对象的函数。我使用了一些与`random`模块不同的功能。`random.randint()`给出两个极端之间的整数。问题是它遵循一个统一的概率分布，这意味着区间中的任何数字都有相同的出现概率。

因此，在处理大量数据时，如果使用均匀分布来分布装置，则得到的结果将非常相似。因此，我选择使用`triangular`和`gauss`，用于`clicks`和`impressions`。他们使用不同的概率分布，这样我们最终会看到一些更有趣的东西。

为了确保我们使用相同的术语：`clicks`表示活动广告的点击次数，`budget`是分配给活动的总金额，`spent`是已经花费了多少钱，`impressions`是作为资源获取活动的次数，无论在活动上执行了多少次单击，都可以从其来源获取。通常，印象的数量大于点击的数量。

现在我们有了这些数据，是时候把它们放在一起了：

`#7`

```py
def get_data(users):
    data = []
    for user in users:
        campaigns = [get_campaign_data()
                     for _ in range(random.randint(2, 8))]
        data.append({'user': user, 'campaigns': campaigns})
    return data
```

正如您所看到的，`data`中的每个项目都是一个包含用户的 dict 以及与该用户关联的活动列表。

## 清理数据

让我们开始清理数据：

`#8`

```py
rough_data = get_data(users)
rough_data[:2]  # let's take a peek
```

我们模拟从源获取数据，然后检查它。笔记本是检查步骤的完美工具。您可以根据需要改变粒度。`rough_data`中的第一项如下：

```py
[{'campaigns': [{'cmp_bgt': 130532,
 'cmp_clicks': 25576,
 'cmp_impr': 500001,
 'cmp_name': 'AKX_20150826_20170305_35-50_B_EUR',
 'cmp_spent': 57574},
 ... omit ...
 {'cmp_bgt': 884396,
 'cmp_clicks': 10955,
 'cmp_impr': 499999,
 'cmp_name': 'KTR_20151227_20151231_45-55_B_GBP',
 'cmp_spent': 318887}],
 'user': '{"age": 44, "username": "jacob43",
 "name": "Holland Strosin",
 "email": "humberto.leuschke@brakus.com",
 "address": "1038 Runolfsdottir Parks\\nElmapo...",
 "gender": "M"}'}]

```

所以，我们现在就开始研究它。

`#9`

```py
data = []
for datum in rough_data:
    for campaign in datum['campaigns']:
        campaign.update({'user': datum['user']})
        data.append(campaign)
data[:2]  # let's take another peek
```

我们需要做的第一件事是对数据帧进行反规范化，以便能够向数据帧提供这些数据。这意味着将数据转换为一个列表，其中的项目是活动目录，并添加了相应的用户目录。用户将在其所属的每个活动中重复。`data`中的第一项如下：

```py
[{'cmp_bgt': 130532,
 'cmp_clicks': 25576,
 'cmp_impr': 500001,
 'cmp_name': 'AKX_20150826_20170305_35-50_B_EUR',
 'cmp_spent': 57574,
 'user': '{"age": 44, "username": "jacob43",
 "name": "Holland Strosin",
 "email": "humberto.leuschke@brakus.com",
 "address": "1038 Runolfsdottir Parks\\nElmaport...",
 "gender": "M"}'}]

```

您可以看到，用户对象已被带到活动 dict 中，该活动 dict 在每次活动中都会重复。

## 创建数据帧

现在是创建`DataFrame`的时候了：

`#10`

```py
df = DataFrame(data)
df.head()
```

最后，我们将创建`DataFrame`并使用`head`方法检查前五行。您应该看到如下内容：

![Creating the DataFrame](images/4715_09_02.jpg)

Jupyter 自动将`df.head()`调用的输出呈现为 HTML。为了获得基于文本的输出，只需在`print`调用中包装`df.head()`。

`DataFrame`结构非常强大。它允许我们对它的内容进行大量的操作。您可以按行、列、数据聚合和许多其他操作进行筛选。如果使用纯 Python 处理数据，您可以使用行或列进行操作，而不必付出时间代价。之所以会这样，是因为在幕后，`pandas`利用了 NumPy 库的强大功能，而 NumPy 库本身从其核心的底层实现中获得了难以置信的速度。NumPy 代表**数值 Python**，它是数据科学环境中使用最广泛的库之一。

使用数据框架，我们可以将 NumPy 的强大功能与类似电子表格的功能结合起来，这样我们就能够以类似于分析师的方式处理数据。只是，我们用代码来做。

但让我们回到我们的项目。让我们来看两种快速鸟瞰数据的方法：

`#11`

```py
df.count()
```

`count`生成每列中所有非空单元格的计数。这有助于您了解数据的稀疏程度。在本例中，我们没有缺失值，因此输出为：

```py
cmp_bgt       4974
cmp_clicks    4974
cmp_impr      4974
cmp_name      4974
cmp_spent     4974
user          4974
dtype: int64

```

美好的我们有 4974 行，数据类型是整数（`dtype: int64`表示长整数，因为它们各占 64 位）。考虑到我们有 1000 个用户，每个用户的活动数量是 2 到 8 之间的随机数，我们完全符合我的预期。

`#12`

```py
df.describe()
```

`describe`是一种很好的快速反思方式：

```py
 cmp_bgt    cmp_clicks       cmp_impr      cmp_spent
count    4974.000000   4974.000000    4974.000000    4974.000000
mean   503272.706876  40225.764978  499999.495979  251150.604343
std    289393.747465  21910.631950       2.035355  220347.594377
min      1250.000000    609.000000  499992.000000     142.000000
25%    253647.500000  22720.750000  499998.000000   67526.750000
50%    508341.000000  36561.500000  500000.000000  187833.000000
75%    757078.250000  55962.750000  500001.000000  385803.750000
max    999631.000000  98767.000000  500006.000000  982716.000000

```

如您所见，它为我们提供了几个度量，如`count`、`mean`、`std`（标准差）、`min`、`max`，并显示了数据在各个象限中的分布情况。多亏了这种方法，我们可以大致了解数据的结构。

让我们看看哪三项活动的预算最高和最低：

`#13`

```py
df.sort_index(by=['cmp_bgt'], ascending=False).head(3)
```

此给出以下输出（截断）：

```py
 cmp_bgt  cmp_clicks  cmp_impr                  cmp_name
4655   999631       15343    499997  AKX_20160814_20180226_40
3708   999606       45367    499997  KTR_20150523_20150527_35
1995   999445       12580    499998  AKX_20141102_20151009_30

```

并且（`#14`）对`.tail(3)`的调用，向我们显示预算最低的。

### 打开活动名称的包装

现在是将复杂性提高一点的时候了。首先，我们想摆脱那个可怕的竞选名称（`cmp_name`。我们需要将它分解成几个部分，并将每个部分放在一个专用的列中。为此，我们将使用**系列**对象的`apply`方法。

`pandas.core.series.Series`类基本上是一个围绕数组的强大包装器（可以将其视为一个具有增强功能的列表）。我们可以通过访问`DataFrame`对象来推断`Series`对象，访问方式与访问 dict 中的键相同，我们可以调用`Series`对象上的`apply`，该对象将运行一个函数，将`Series`中的每个项提供给它。我们将结果合成一个新的`DataFrame`，然后与我们所爱的`df`一起加入`DataFrame`。

`#15`

```py
def unpack_campaign_name(name):
    # very optimistic method, assumes data in campaign name
    # is always in good state
    type_, start, end, age, gender, currency = name.split('_')
    start = parse(start).date
    end = parse(end).date
    return type_, start, end, age, gender, currency

campaign_data = df['cmp_name'].apply(unpack_campaign_name)
campaign_cols = [
    'Type', 'Start', 'End', 'Age', 'Gender', 'Currency']
campaign_df = DataFrame(
    campaign_data.tolist(), columns=campaign_cols, index=df.index)
campaign_df.head(3)
```

在`unpack_campaign_name`内，我们将活动`name`分为几个部分。我们使用`delorean.parse()`从这些字符串中获取一个合适的日期对象（`delorean`使之非常容易，不是吗？），然后返回对象。快速浏览最后一行可以发现：

```py
 Type       Start         End    Age Gender Currency
0  KTR  2016-06-16  2017-01-24  20-30      M      EUR
1  BYU  2014-10-25  2015-07-31  35-50      B      USD
2  BYU  2015-10-26  2016-03-17  35-50      M      EUR

```

美好的重要的一点是：即使日期显示为字符串，它们也只是`DataFrame`中托管的真实`date`对象的表示。

另一件非常重要的事情：当连接两个数据帧实例时，它们必须具有相同的索引，否则`pandas`将无法知道哪些行与哪些行匹配。因此，当我们创建`campaign_df`时，我们将其索引设置为`df`中的索引。这使我们能够加入他们。创建此数据框时，我们还传递列名称。

`#16`

```py
df = df.join(campaign_df)
```

在连接之后，我们看了一眼，希望看到匹配的数据（输出被截断）：

`#17`

```py
df[['cmp_name'] + campaign_cols].head(3)
```

给予：

```py
 cmp_name Type       Start         End
0  KTR_20160616_20170124_20-30_M_EUR  KTR  2016-06-16  2017-01-24
1  BYU_20141025_20150731_35-50_B_USD  BYU  2014-10-25  2015-07-31
2  BYU_20151026_20160317_35-50_M_EUR  BYU  2015-10-26  2016-03-17

```

正如你所看到的，加入是成功的；活动名称和单独的列公开相同的数据。你看到我们在那里做什么了吗？我们使用方括号语法访问`DataFrame`，并传递列名列表。这将产生一个全新的`DataFrame`，其中包含这些列（顺序相同），我们将其称为`head()`。

### 解包用户数据

我们现在对每一段`user`JSON 数据执行完全相同的操作。我们在`user`系列上调用`apply`，运行`unpack_user_json`函数，该函数获取 JSON`user`对象并将其转换为字段列表，然后我们可以将其注入全新的数据帧`user_df`。之后，我们将加入`user_df`和`df`，就像我们加入`campaign_df`一样。

`#18`

```py
def unpack_user_json(user):
    # very optimistic as well, expects user objects
    # to have all attributes
    user = json.loads(user.strip())
    return [
        user['username'],
        user['email'],
        user['name'],
        user['gender'],
        user['age'],
        user['address'],
    ]

user_data = df['user'].apply(unpack_user_json)
user_cols = [
    'username', 'email', 'name', 'gender', 'age', 'address']
user_df = DataFrame(
    user_data.tolist(), columns=user_cols, index=df.index)
```

非常类似于之前的操作，不是吗？这里我们还应该注意，在创建`user_df`时，我们需要指导`DataFrame`关于列名，以及非常重要的索引。让我们加入（`#19`）并快速浏览一下（`#20`：

```py
df = df.join(user_df)
df[['user'] + user_cols].head(2)
```

结果表明一切进展顺利。我们很好，但我们还没有结束。

如果你在牢房里打电话给`df.columns`，你会发现我们的专栏仍然有难听的名字。让我们改变这一点：

`#21`

```py
better_columns = [
    'Budget', 'Clicks', 'Impressions',
    'cmp_name', 'Spent', 'user',
    'Type', 'Start', 'End',
    'Target Age', 'Target Gender', 'Currency',
    'Username', 'Email', 'Name',
    'Gender', 'Age', 'Address',
]
df.columns = better_columns
```

好的现在，除了`'cmp_name'`和`'user'`之外，我们只有好名字。

完成`datasetNext`步骤将添加一些额外的列。对于每个活动，我们都有点击量和印象量，我们也有花费。这允许我们引入三个测量比率：**CTR**、**CPC**和**CPI**。它们分别代表**点击率**、**每次点击成本**和**每次印象成本**。

最后两个很容易理解，但 CTR 却不是。只需说点击次数与印象次数之比就足够了。它为您提供了一个衡量每个印象中在一个活动广告上进行了多少次点击的指标：这个数字越高，广告在吸引用户点击方面就越成功。

`#22`

```py
def calculate_extra_columns(df):
    # Click Through Rate
    df['CTR'] = df['Clicks'] / df['Impressions']
    # Cost Per Click
    df['CPC'] = df['Spent'] / df['Clicks']
    # Cost Per Impression
    df['CPI'] = df['Spent'] / df['Impressions']
calculate_extra_columns(df)
```

我把它写成函数，但我可以把代码写在单元格里。这不重要。我想让你们注意的是，我们正在添加这三列，每列有一行代码，但是`DataFrame`会自动将操作（在本例中为除法）应用到相应列中的每对单元格。因此，即使它们被屏蔽为三个分区，它们实际上是*4974*3*分区，因为它们是为每一行执行的。熊猫为我们做了很多工作，也很好地隐藏了它的复杂性。

函数`calculate_extra_columns,`接受一个`DataFrame`，并直接作用于它。这种操作模式称为**就地**。你还记得`list.sort()`是如何整理名单的吗？这是同样的交易。

我们可以通过过滤相关列并调用`head`来查看结果。

`#23`

```py
df[['Spent', 'Clicks', 'Impressions',
    'CTR', 'CPC', 'CPI']].head(3)
```

这向我们表明，每行的计算都是正确的：

```py
 Spent  Clicks  Impressions       CTR       CPC       CPI
0   57574   25576       500001  0.051152  2.251095  0.115148
1  226319   61247       499999  0.122494  3.695185  0.452639
2    4354   15582       500004  0.031164  0.279425  0.008708

```

现在，我想手动验证第一行结果的准确性：

`#24`

```py
clicks = df['Clicks'][0]
impressions = df['Impressions'][0]
spent = df['Spent'][0]
CTR = df['CTR'][0]
CPC = df['CPC'][0]
CPI = df['CPI'][0]
print('CTR:', CTR, clicks / impressions)
print('CPC:', CPC, spent / clicks)
print('CPI:', CPI, spent / impressions)
```

它产生以下输出：

```py
CTR: 0.0511518976962 0.0511518976962
CPC: 2.25109477635 2.25109477635
CPI: 0.115147769704 0.115147769704

```

这正是我们在前面的输出中看到的。当然，我通常不需要这样做，但我想告诉你如何用这种方式进行计算。您可以访问一个系列（一列），方法是将其名称传递到方括号中的`DataFrame`，然后按其位置访问每一行，就像使用常规列表或元组一样。

我们的`DataFrame`差不多完成了。我们现在缺少的只是一列，它告诉我们活动的持续时间，还有一列告诉我们一周中的哪一天对应于每个活动的开始日期。这使我能够详细介绍如何使用日期对象。

`#25`

```py
def get_day_of_the_week(day):
    number_to_day = dict(enumerate(calendar.day_name, 1))
    return number_to_day[day.isoweekday()]

def get_duration(row):
    return (row['End'] - row['Start']).days

df['Day of Week'] = df['Start'].apply(get_day_of_the_week)
df['Duration'] = df.apply(get_duration, axis=1)
```

我们在这里使用了两种不同的技术，但首先是代码。

`get_day_of_the_week`接受日期对象。如果您无法理解它的作用，请在阅读解释之前花一些时间尝试自己理解。使用由内而外的技术，就像我们以前做过几次一样。

所以，我相信你现在已经知道了，如果你在`list`电话中输入`calendar.day_name`，你会得到`['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']`。这意味着，如果我们从 1 开始枚举`calendar.day_name`，我们会得到`(1, 'Monday')`、`(2, 'Tuesday')`等对。如果我们把这些对输入一个 dict，我们会得到一周中作为数字（1，2，3，…）的几天和它们的名字之间的映射。创建映射时，为了获得一天的名称，我们只需要知道它的编号。为了得到它，我们打电话`date.isoweekday()`，它告诉我们该日期是一周中的哪一天（作为一个数字）。你把它输入地图，砰！你有今天的名字。

`get_duration`也是有趣的。首先，请注意它需要一整行，而不仅仅是一个值。它的主体是我们在活动结束日期和开始日期之间进行减法运算。减去日期对象后，结果是一个`timedelta`对象，表示给定的时间量。我们取其`.days`属性的值。就这么简单。

现在，我们可以介绍有趣的部分，这两个函数的应用。

第一个应用程序是在`Series`对象上执行的，就像我们之前对`'user'`和`'cmp_name'`所做的一样，这里没有什么新的内容。

第二个应用于整个数据帧，为了指示 Pandas 对行执行该操作，我们通过`axis=1`。

我们可以很容易地验证结果，如下所示：

`#26`

```py
df[['Start', 'End', 'Duration', 'Day of Week']].head(3)
```

产量：

```py
 Start         End  Duration Day of Week
0  2015-08-26  2017-03-05       557   Wednesday
1  2014-10-15  2014-12-19        65   Wednesday
2  2015-02-22  2016-01-14       326      Sunday

```

因此，我们现在知道 2015 年 8 月 26 日至 2017 年 3 月 5 日之间有 557 天，2015 年 8 月 26 日是星期三。

如果您想知道这是为了什么，我将提供一个例子。想象一下，你有一个与通常在周日举行的体育赛事相关的活动。您可能希望根据天数检查数据，以便将它们与您的各种测量值关联起来。我们不打算在这个项目中这样做，但如果只是为了在数据帧上调用`apply()`的不同方式，那么这是很有用的。

### 清理一切

既然我们有了我们想要的一切，现在是时候做最后的清理了：记住我们还有`'cmp_name'`和`'user'`列。那些现在没用了，所以他们必须走了。另外，我想对数据框中的列重新排序，以便它与它现在包含的数据更相关。为了做到这一点，我们只需要在我们想要的列列表中过滤`df`。我们将得到一个全新的数据帧，可以重新分配给`df`本身。

`#27`

```py
final_columns = [
    'Type', 'Start', 'End', 'Duration', 'Day of Week', 'Budget',
    'Currency', 'Clicks', 'Impressions', 'Spent', 'CTR', 'CPC',
    'CPI', 'Target Age', 'Target Gender', 'Username', 'Email',
    'Name', 'Gender', 'Age'
]
df = df[final_columns]
```

我已经在开始时对活动信息进行了分组，然后是度量，最后是用户数据。现在，我们的数据框架已经干净，可以检查了。

在我们开始疯狂使用图形之前，先拍下数据帧的快照，这样我们就可以轻松地从文件中重建数据帧，而不必重复我们在这里所做的所有步骤。一些分析员可能希望以电子表格的形式进行分析，以进行与我们希望进行的分析不同的分析，所以让我们看看如何将数据帧保存到文件中。做起来容易，说起来难。

## 将数据帧保存到文件中

我们可以用许多不同的方式保存数据帧。您可以键入`df.to_`，然后按*选项卡*弹出自动完成，查看所有可能的选项。

我们将以三种不同的格式保存数据帧，只是为了好玩：**逗号分隔值**（**CSV**）、JSON 和 Excel 电子表格。

`#28`

```py
df.to_csv('df.csv')
```

`#29`

```py
df.to_json('df.json')
```

`#30`

```py
df.to_excel('df.xls')
```

CSV 文件如下所示（输出被截断）：

```py
Type,Start,End,Duration,Day of Week,Budget,Currency,Clicks,Impres
0,GRZ,2015-03-15,2015-11-10,240,Sunday,622551,GBP,35018,500002,787
1,AKX,2016-06-19,2016-09-19,92,Sunday,148219,EUR,45185,499997,6588
2,BYU,2014-09-25,2016-07-03,647,Thursday,537760,GBP,55771,500001,3

```

JSON 是这样的（同样，输出被截断）：

```py
{
 "Type": {
 "0": "GRZ",
 "1": "AKX",
 "2": "BYU",

```

因此，以多种不同的格式保存数据框非常容易，好消息是，相反的情况也是如此：将电子表格加载到数据框中非常容易。熊猫背后的程序员们为减轻我们的任务付出了很大的努力，这是值得感激的。

## 可视化结果

最后是多汁的部分。在本节中，我们将可视化一些结果。从数据科学的角度来看，我对深入分析不太感兴趣，特别是因为数据是完全随机的，但尽管如此，这段代码将让您从图形和其他特性开始。

我在生活中学到了一点，这可能会让你感到惊讶，那就是*外表也很重要*，所以当你展示你的结果时，你要尽最大努力*让它们漂亮*。

我不会试图向你们证明最后的陈述是多么真实，但我真的相信它。如果您回忆起单元格`#1`的最后一行：

```py
# make the graphs nicer
pd.set_option('display.mpl_style', 'default')
```

它的目的是使我们将在本节中看到的图形更漂亮一点。

好的，那么，首先我们要指导笔记本，我们要使用`matplotlib``inline`。这意味着，当我们要求 Pandas 绘制某些内容时，我们将在单元输出帧中呈现结果。为此，我们只需要一个简单的说明：

`#31`

```py
%matplotlib inline
```

当您从控制台通过传递参数启动笔记本电脑时，您也可以指示笔记本电脑执行此操作，但我也希望以这种方式向您展示，因为仅仅因为您想要打印某些内容而必须重新启动笔记本电脑可能会很烦人。通过这种方式，你可以在飞行中完成它，然后继续工作。

接下来，我们将在`pylab`上设置一些参数。这用于打印目的，它将删除未找到字体的警告。我建议你不要执行这一行，继续前进。如果收到字体丢失的警告，请返回此单元格并运行它。

`#32`

```py
import pylab
pylab.rcParams.update({'font.family' : 'serif'})
```

这基本上告诉 Pylab 使用第一个可用的衬线字体。它简单但有效，你也可以尝试其他字体。

现在数据帧已经完成，让我们再次运行`df.describe()`（`#33`。结果应该如下所示：

![Visualizing the results](images/4715_09_03.jpg)

这种快速的结果非常适合那些有 20 秒时间奉献给你，只需要粗略数字的经理。

### 注

再一次，请记住我们的活动有不同的货币，所以这些数字实际上是没有意义的。这里的重点是演示数据帧功能，而不是对实际数据进行正确或详细的分析。

或者，图形通常比带数字的表格好得多，因为它更容易阅读，并且可以立即提供反馈。那么，让我们把每个活动的四条信息绘制出来：预算、支出、点击和印象。

`#34`

```py
df[['Budget', 'Spent', 'Clicks', 'Impressions']].hist(
    bins=16, figsize=(16, 6));
```

我们推断这四列（这将为我们提供另一个仅由这些列构成的数据帧），并对其调用直方图`hist()`方法。我们对箱子和数字大小进行了一些测量，但基本上一切都是自动完成的。

一件重要的事情：由于此指令是此单元格中的唯一指令（也就是说，它是最后一条指令），笔记本将在绘制图形之前打印其结果。要抑制这种行为并只绘制图形而不打印，只需在末尾添加一个分号（您认为我是在回忆 Java，不是吗？）。以下是图表：

![Visualizing the results](images/4715_09_04.jpg)

它们很漂亮，不是吗？你注意到衬线字体了吗？那些数字的含义是什么？如果你回到`#6`并看看我们生成数据的方式，你会发现所有这些图都非常有意义。

**预算**仅仅是一个区间内的随机整数，因此我们期望*均匀分布*，我们得到了它；这实际上是一条不变的线。

**花费**也是*均匀分布*，但其区间的高端是预算，预算在移动，这意味着我们应该期待类似于向右递减的二次夸张。它也在那里。

**点击**是以*三角分布*生成的，平均值约为区间大小的 20%，你可以看到峰值就在那里，在左侧约 20%。

最后，**印象**是一个*高斯分布*，这是一个假设著名钟形的分布。平均值正好在中间，标准偏差为 2。您可以看到图形与这些参数匹配。

好的让我们画出我们计算的度量：

`#35`

```py
df[['CTR', 'CPC', 'CPI']].hist(
    bins=20, figsize=(16, 6));
```

![Visualizing the results](images/4715_09_05.jpg)

我们可以看到，每次点击的成本高度向左倾斜，这意味着大多数 CPC 值都非常低。每个印模的成本形状相似，但不太极端。

现在，所有这些都很好，但如果您只想分析数据的特定部分，您会如何做呢？我们可以对一个数据帧应用一个掩码，这样我们就可以得到另一个只有满足掩码条件的行的掩码。这就像应用一个全局行方式的`if`子句。

`#36`

```py
mask = (df.Spent > 0.75 * df.Budget)
df[mask][['Budget', 'Spent', 'Clicks', 'Impressions']].hist(
    bins=15, figsize=(16, 6), color='g');
```

在本例中，我准备了一个掩码来过滤掉花费小于或等于预算 75%的所有行。换句话说，我们将只包括那些花费了至少四分之三预算的活动。请注意，在掩码中，我向您展示了一种请求数据帧列的替代方法，即使用直接属性访问（`object.property_name`，而不是类似 dict 的访问（`object['property_name']`。如果`property_name`是一个有效的 Python 名称，那么您可以交替使用这两种方法（JavaScript 也是这样工作的）。

应用掩码的方式与使用密钥访问 dict 的方式相同。当你对一个数据帧应用一个掩码时，你会得到另一个掩码，我们只选择这个掩码上的相关列，然后再次调用`hist()`。这一次，只是为了好玩，我们希望结果被涂成绿色：

![Visualizing the results](images/4715_09_06.jpg)

请注意除了花费的图形外，图形的形状没有太大变化，这是非常不同的。原因是，我们只要求支出至少占预算 75%的行。这意味着我们只包括支出接近预算的行。预算数字来自统一分配。因此，很明显，花掉的钱现在正呈这种形状。如果你把边界变得更紧，要求 85%或更多，你会看到花费越来越像预算。

现在让我们要求一些不同的东西。按一周中的哪一天分组的花费、点击量和印象量如何？

`#37`

```py
df_weekday = df.groupby(['Day of Week']).sum()
df_weekday[['Impressions', 'Spent', 'Clicks']].plot(
    figsize=(16, 6), subplots=True);
```

第一行通过在`df`上请求`'Day of Week'`分组来创建一个新的`DataFrame``df_weekday`。用于聚合数据的函数是加法。

第二行使用列名列表获取`df_weekday`片段，这是我们现在已经习惯的。在结果上我们称之为`plot()`，这与`hist()`有点不同。选项`subplots=True`使`plot`绘制三个独立的图形：

![Visualizing the results](images/4715_09_07.jpg)

有趣的是，我们可以看到大部分的活动都发生在周四。如果这是有意义的数据，那么这可能是向我们的客户提供的重要信息，这就是我向您展示这个示例的原因。

请注意，日期是按字母顺序排列的，这会使它们有点混乱。你能想出一个快速的解决方案来解决这个问题吗？我将把它留给你作为一个练习来想出一些东西。

让我们用更多的东西来结束本演示部分。首先，一个简单的聚合。我们希望在`'Target Gender'`和`'Target Age'`上进行聚合，并显示`'Impressions'`和`'Spent'`。对于这两种情况，我们都希望看到平均值和标准偏差。

`#38`

```py
agg_config = {
    'Impressions': {
        'Mean Impr': 'mean',
        'Std Impr': 'std',
    },
    'Spent': ['mean', 'std'],
}

df.groupby(['Target Gender', 'Target Age']).agg(agg_config)
```

做这件事很容易。我们将准备一本字典，用作配置。我向你展示了两种选择。我们对`'Impressions'`使用了更好的格式，其中我们传递了一个嵌套的 dict，其中描述/函数作为键/值对。另一方面，对于`'Spent'`，我们只使用一个简单的列表，其中只包含函数名。

然后，我们对`'Target Gender'`和`'Target Age'`列进行分组，并将配置 dict 传递给`agg()`方法。结果被截断并重新排列一点以使其适合，如下所示：

```py
 Impressions              Spent
 Mean Impr  Std Impr    mean            std
Target Target 
Gender Age 
B      20-25           500000  2.189102  239882  209442.168488
 20-30           500000  2.245317  271285  236854.155720
 20-35           500000  1.886396  243725  174268.898935
 20-40           499999  2.100786  247740  211540.133771
 20-45           500000  1.772811  148712  118603.932051
...                    ...       ...     ...            ...
M      20-25           500000  2.022023  212520  215857.323228
 20-30           500000  2.111882  292577  231663.713956
 20-35           499999  1.965177  255651  222790.960907
 20-40           499999  1.932473  282515  250023.393334
 20-45           499999  1.905746  271077  219901.462405

```

当然，这是文本表示，但也可以使用 HTML 表示。您可以看到，`Spent`有`mean`和`std`列，它们的标签只是函数名，而`Impressions`有我们添加到配置 dict 中的漂亮标题。

在我们结束这一章之前，让我们再做一件事。我想给你们看一个叫做**透视表**的东西。这是数据环境中的一个流行语，所以像这样一个例子，尽管非常简单，却是必须的。

`#39`

```py
pivot = df.pivot_table(
    values=['Impressions', 'Clicks', 'Spent'],
    index=['Target Age'],
    columns=['Target Gender'],
    aggfunc=np.sum
)
pivot
```

我们创建一个数据透视表，显示目标年龄与印象、点击次数和花费之间的相关性。最后三项将按目标性别细分。用于计算结果的聚合函数是`numpy.sum`函数（如果我没有指定任何内容，`numpy.mean`将是默认值）。

创建透视表后，我们只需使用单元格中的最后一行打印它，下面是结果的裁剪：

![Visualizing the results](images/4715_09_08.jpg)

当数据有意义时，它非常清晰，提供了非常有用的信息。

就这样！我将留给你们去发现更多关于 Ipyton、Jupyter 和数据科学的精彩世界。我强烈建议您熟悉笔记本电脑环境。它比控制台好得多，使用起来非常实用和有趣，你甚至可以用它制作幻灯片和文档。

# 我们将从这里走向何方？

数据科学确实是一门迷人的学科。正如我在导言中所说，那些想要深入研究其曲折的人需要接受良好的数学和统计培训。使用插值错误的数据会使任何有关该数据的结果变得无用。对于外推错误或采样频率错误的数据也是如此。为了给你一个例子，想象一个队列中排列的个体群体。如果出于某种原因，该人群的性别在男性和女性之间交替，那么队列将是这样的：F-M-F-M-F-M-F-M-M-F-M-F。。。

如果你只对偶数元素进行抽样，你会得出结论，人口中只有男性，而对奇数元素进行抽样会得出完全相反的结果。

当然，我知道这只是一个愚蠢的例子，但相信我，在这个领域很容易犯错误，特别是在处理大数据时，抽样是强制性的，因此，你所做的自省的质量首先取决于抽样本身的质量。

说到数据科学和 Python，以下是您想要了解的主要工具：

*   **NumPy**[http://www.numpy.org/](http://www.numpy.org/) ：这是使用 Python 进行科学计算的基本包。它包含强大的 N 维数组对象、复杂的（广播）函数、集成 C/C++和 Fortran 代码的工具、有用的线性代数、傅立叶变换、随机数功能等等。
*   **Scikit 学习**[http://scikit-learn.org/stable/](http://scikit-learn.org/stable/) ：这可能是 Python 中最流行的机器学习库。它有简单而高效的数据挖掘和数据分析工具，每个人都可以访问，并且可以在各种环境中重用。它基于 NumPy、SciPy 和 Matplotlib 构建。
*   **大熊猫**[http://pandas.pydata.org/](http://pandas.pydata.org/) ：这是一个开放源码、BSD 许可的库，提供高性能、易于使用的数据结构和数据分析工具。我们在整个章节中都用到了它。
*   **伊皮顿**[http://ipython.org/](http://ipython.org/) /Jupyter（[http://jupyter.org/](http://jupyter.org/) ：这些为交互计算提供了丰富的架构。
*   **Matplotlib**[http://matplotlib.org/](http://matplotlib.org/) ：这是一个 Python 2D 绘图库，以各种硬拷贝格式和跨平台的交互环境生成出版物质量的图形。Matplotlib 可用于 Python 脚本、Python 和 IPython 外壳和笔记本、web 应用程序服务器以及六个图形用户界面工具包。
*   **麻麻**[http://numba.pydata.org/](http://numba.pydata.org/) ：这使您能够使用直接用 Python 编写的高性能函数来加速应用程序。通过几个注释，面向数组和数学重的 Python 代码可以及时编译到本机机器指令，类似于 C、C++和 FORTRAN 的性能，而不必切换语言或 Python 解释器。
*   **波基**[http://bokeh.pydata.org/en/latest/](http://bokeh.pydata.org/en/latest/) ：这是一个 Python 交互式可视化库，面向现代 web 浏览器进行演示。它的目标是以 D3.js 的风格提供优雅、简洁的新颖图形构造，同时还提供了在超大数据集或流式数据集上具有高性能交互性的功能。

除了这些单个库之外，您还可以找到类似于**SciPy**（[的生态系统 http://scipy.org/](http://scipy.org/) 和**蟒蛇**（[https://www.continuum.io/](https://www.continuum.io/) ），它将几个不同的包捆绑在一起，为您提供“开箱即用”的功能时尚

在某些系统上安装所有这些工具以及它们的几个依赖项是很困难的，所以我建议您也尝试一下生态系统，看看是否适合使用它们。这可能是值得的。

# 总结

在本章中，我们讨论了数据科学。我们没有试图解释这个极其广泛的主题，而是深入研究了一个项目。我们熟悉了 Jupyter 笔记本和不同的图书馆，如 Pandas、Matplotlib、NumPy。

当然，将所有这些信息压缩成一个章节意味着我只能简单地谈一下我介绍的主题。我希望我们一起经历的项目已经足够全面，能够让你很好地了解在这个领域工作时可能遵循的工作流程。

下一章专门讨论 web 开发。所以，确保你已经准备好了浏览器，我们开始吧！