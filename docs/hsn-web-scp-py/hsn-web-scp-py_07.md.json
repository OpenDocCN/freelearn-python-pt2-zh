["```py\nfrom bs4 import BeautifulSoup\nfrom bs4 import SoupStrainer #,BeautifulSoup\n```", "```py\nhtml_doc=\"\"\"<html><head><title>The Dormouse's story</title></head> <body> <p class=\"title\"><b>The Dormouse's story</b></p> <p class=\"story\">Once upon a time there were three little sisters; and their names were <a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>, <a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and <a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>; and they lived at the bottom of a well.</p> <p class=\"story\">...</p> <h1>Secret agents</h1> <ul>\n <li data-id=\"10784\">Jason Walters, 003: Found dead in \"A View to a Kill\".</li> <li data-id=\"97865\">Alex Trevelyan, 006: Agent turned terrorist leader; James' nemesis in \"Goldeneye\".</li> <li data-id=\"45732\">James Bond, 007: The main man; shaken but not stirred.</li> </ul> </body> </html>\"\"\"\n```", "```py\ntagsA = SoupStrainer(\"a\")\nsoupA = BeautifulSoup(html_doc,'lxml',parse_only=tagsA)\n print(type(soupA))\n<class 'bs4.BeautifulSoup'>\n\nprint(soupA)\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a><a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a><a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n```", "```py\nprint(soupA.prettify())\n\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n Elsie\n</a>\n<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n Lacie\n</a>\n<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\n Tillie\n</a>\n```", "```py\n<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n```", "```py\nprint(soupA.a.has_attr('class'))\nTrue\n\nprint(soupA.a.has_attr('name'))\nFalse\n```", "```py\nprint(soupA.find(\"a\")) #print(soupA.find(name=\"a\"))\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a> print(soupA.find(\"a\",attrs={'class':'sister'}))\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n\nprint(soupA.find(\"a\",attrs={'class':'sister'},text=\"Lacie\"))\n<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n\nprint(soupA.find(\"a\",attrs={'id':'link3'}))\n<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>\n\nprint(soupA.find('a',id=\"link2\"))\n<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n```", "```py\n#find all <a> can also be written as #print(soupA.find_all(name=\"a\")) print(soupA.find_all(\"a\"))  [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n\n#find all <a>, but return only 2 of them\nprint(soupA.find_all(\"a\",limit=2)) #attrs, text\n\n[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>]\n```", "```py\nprint(soupA.find(\"a\",text=re.compile(r'cie'))) #import re\n<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>\n print(soupA.find_all(\"a\",attrs={'id':re.compile(r'3')}))\n[<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n\nprint(soupA.find_all(re.compile(r'a'))) [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>] \n```", "```py\nsoup = BeautifulSoup(html_doc,'lxml')\n print(soup.find_all(\"p\",\"story\")) #class=story\n[<p class=\"story\">Once upon a time there were three little sisters; and their names were\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\nand they lived at the bottom of a well.</p>, <p class=\"story\">...</p>]\n\nprint(soup.find_all(\"p\",\"title\")) #soup.find_all(\"p\",attrs={'class':\"title\"})\n[<p class=\"title\"><b>The Dormouse's story</b></p>]\n```", "```py\nprint(soup.find_all(\"p\",attrs={'class':[\"title\",\"story\"]}))\n[<p class=\"title\"><b>The Dormouse's story</b></p>,\n<p class=\"story\">Once upon a...\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,....\n<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\nand they lived at the bottom of a well.</p>, <p class=\"story\">...</p>]\n\nprint(soup.find_all([\"p\",\"li\"]))\n[<p class=\"title\"><b>The Dormouse's story</b></p>,\n<p class=\"story\">Once...<a class=\"sister\" href=\"http://example.com/elsie\"...., \n<p class=\"story\">...</p>, \n<li data-id=\"10784\">Jason Walters, 003:....</li>,<li....., \n<li data-id=\"45732\">James Bond, 007: The main man; shaken but not stirred.</li>]\n```", "```py\nprint(soup.find_all(string=\"Elsie\")) #text=\"Elsie\"\n['Elsie']\n\nprint(soup.find_all(text=re.compile(r'Elsie'))) #import re\n['Elsie']\n\nprint(soup.find_all(\"a\",string=\"Lacie\")) #text=\"Lacie\"\n[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link2\">Lacie</a>]\n```", "```py\nfor li in soup.ul.find_all('li'):\n    print(li.name, ' > ',li.get('data-id'),' > ', li.text)\n\nli > 10784 > Jason Walters, 003: Found dead in \"A View to a Kill\".\nli > 97865 > Alex Trevelyan, 006: Agent turned terrorist leader; James' nemesis in \"Goldeneye\".\nli > 45732 > James Bond, 007: The main man; shaken but not stirred.\n```", "```py\nprint(soupA.a) #tag a\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n\nprint(soup.li) #tag li\n<li data-id=\"10784\">Jason Walters, 003: Found dead in \"A View to a Kill\".</li>\n\nprint(soup.p)\n<p class=\"title\"><b>The Dormouse's story</b></p>\n\nprint(soup.p.b) #tag p and b\n<b>The Dormouse's story</b>\n\nprint(soup.ul.find('li',attrs={'data-id':'45732'}))\n<li data-id=\"45732\">James Bond, 007: The main man; shaken but not stirred.</li>\n```", "```py\nprint(soup.ul.find('li',attrs={'data-id':'45732'}).text)\nJames Bond, 007: The main man; shaken but not stirred.\n\nprint(soup.p.text) #get_text()\nThe Dormouse's story\n\nprint(soup.li.text)\nJason Walters, 003: Found dead in \"A View to a Kill\".\n\nprint(soup.p.string)\nThe Dormouse's story\n```", "```py\nprint(list(soup.find('p','story').children))\n['Once upon a time there were three little sisters; and their names were\\n', <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, ',\\n', <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, ' and\\n', <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>, ';\\nand they lived at the bottom of a well.']\n\nprint(list(soup.find('p','story').contents))\n['Once upon a time there were three little sisters; and their names were\\n', <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, ',\\n', <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, ' and\\n', <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>, ';\\nand they lived at the bottom of a well.']\n\nprint(list(soup.find('p','story').descendants))\n['Once upon a time there were three little sisters; and their names were\\n', <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, 'Elsie', ',\\n', <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, 'Lacie', ' and\\n', <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>, 'Tillie', ';\\nand they lived at the bottom of a well.']\n```", "```py\n#using List Comprehension Technique\nprint([a.name for a in soup.find('p','story').children])\n[None, 'a', None, 'a', None, 'a', None]\n\nprint([{'tag':a.name,'text':a.text,'class':a.get('class')} for a in soup.find('p','story').children if a.name!=None])\n[{'tag': 'a', 'text': 'Elsie', 'class': ['sister']}, {'tag': 'a', 'text': 'Lacie', 'class': ['sister']}, {'tag': 'a', 'text': 'Tillie', 'class': ['sister']}]\n\nprint([a.name for a in soup.find('p','story').descendants])\n[None, 'a', None, None, 'a', None, None, 'a', None, None]\n\nprint(list(filter(None,[a.name for a in soup.find('p','story').descendants])))\n['a', 'a', 'a']\n```", "```py\nprint(soup.find('p','story').findChildren())\n[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n\nprint(soup.find('p','story').findChild()) #soup.find('p','story').find()\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n```", "```py\n#print parent element of <a> with class=sister\nprint(soup.find('a','sister').parent)\n<p class=\"story\">Once upon a time there were three little sisters; and their names were\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\nand they lived at the bottom of a well.</p>\n\n#print parent element name of <a> with class=sister\nprint(soup.find('a','sister').parent.name)\np\n\n#print text from parent element of <a> with class=sister\nprint(soup.find('a','sister').parent.text)\nOnce upon a time there were three little sisters; and their names were\nElsie,\nLacie and\nTillie;\nand they lived at the bottom of a well.\n```", "```py\nfor element in soup.find('a','sister').parents:\n    print(element.name)\n\np\nbody\nhtml #complete HTML\n[document]  #soup object\n```", "```py\n#find single Parent for selected <a> with class=sister \nprint(soup.find('a','sister').findParent())\n\n<p class=\"story\">Once upon a time there were three little sisters; and their names were\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\nand they lived at the bottom of a well.</p>\n\n#find Parents for selected <a> with class=sister \nprint(soup.find('a','sister').findParents())\n\n[<p class=\"story\">Once upon a time there were three little sisters; and their names were\n<a class=\"sister\".........Tillie</a>;and they lived at the bottom of a well.</p>,\n<body><p class=\"title\"><b>The Dormouse's story</b></p>\n<p class=\"story\">Once upon........... <li data-id=\"45732\">James Bond, 007: The main man; shaken but not stirred.</li> </ul> </body>, \n<html><head><title>The Dormouse's story</title></head><body><p class=\"title\"><b>The Dormouse's story</b></p> ........... </ul> </body></html>,\n<html><head><title>The Dormouse's story</title></head><body><p class=\"title\"><b>The Dormouse's story</b></p>...........</body></html>]\n```", "```py\nprint(soup.find('p','story').next)\nOnce upon a time there were three little sisters; and their names were\n\nprint(soup.find('p','story').next.next)\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n\nprint(soup.find('p','story').next_element)\nOnce upon a time there were three little sisters; and their names were\n\nprint(soup.find('p','story').next_element.next_element)\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n\nprint(soup.find('p','story').next_element.next_element.next_element)\nElsie\n```", "```py\nprint(soup.find('p','story').previous) #returns empty or new-line. print(soup.find('p','title').next.next.next) #returns empty or newline similar to code above\n\nprint(soup.find('p','story').previous.previous)\nThe Dormouse's story\n\nprint(soup.find('p','story').previous_element) #returns empty or new-line. \nprint(soup.find('p','story').previous_element.previous_element)\nThe Dormouse's story\n\nprint(soup.find('p','story').previous_element.previous_element.previous_element)\n<b>The Dormouse's story</b>\n```", "```py\nprint(soup.find('p','title').next.next.previous.previous)\n\n<p class=\"title\"><b>The Dormouse's story</b></p>\n```", "```py\nfor element in soup.find('ul').next_elements:\n    print(element)\n\n<li data-id=\"10784\">Jason Walters, 003: Found dead in \"A View to a Kill\".</li>\nJason Walters, 003: Found dead in \"A View to a Kill\".\n\n<li data-id=\"97865\">Alex Trevelyan, 006: Agent ............. \"Goldeneye\".</li>\nAlex Trevelyan, 006: Agent turned terrorist leader; James' nemesis in \"Goldeneye\".\n\n<li data-id=\"45732\">James Bond, 007: The main man; shaken but not stirred.</li>\nJames Bond, 007: The main man; shaken but not stirred.\n```", "```py\nprint(soup.find('p','story').next)\nOnce upon a time there were three little sisters; and their names were\n\nprint(soup.find('p','story').next_element)\nOnce upon a time there were three little sisters; and their names were\n\nprint(soup.find('p','story').find_next()) #element after next_element\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n\nprint(soup.find('p','story').find_next('h1'))\n<h1>Secret agents</h1>\n```", "```py\nprint(soup.find('p','story').find_all_next())\n[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>, <p class=\"story\">...</p>, <h1>Secret agents</h1>, <ul>\n<li data-id=\"10784\">Jason Walters, 003: Found dead in \"A View to a Kill\".</li>\n<li data-id=\"97865\">Alex Trevelyan, 006: Agent turned terrorist leader; James' nemesis in \"Goldeneye\".</li>\n<li data-id=\"45732\">James Bond, 007: The main man; shaken but not stirred.</li>\n</ul>, <li data-id=\"10784\">Jason Walters, 003: Found dead in \"A View to a Kill\".</li>, <li data-id=\"97865\">Alex Trevelyan, 006: Agent turned terrorist leader; James' nemesis in \"Goldeneye\".</li>, <li data-id=\"45732\">James Bond, 007: The main man; shaken but not stirred.</li>]\n\nprint(soup.find('p','story').find_all_next('li',limit=2))\n[<li data-id=\"10784\">Jason Walters, 003: Found dead in \"A View to a Kill\".</li>, <li data-id=\"97865\">Alex Trevelyan, 006: Agent turned terrorist leader; James' nemesis in \"Goldeneye\".</li>]\n```", "```py\nprint(soup.find('ul').previous.previous.previous)\n<h1>Secret agents</h1>\n\nprint(soup.find('ul').find_previous())\n<h1>Secret agents</h1>\n\nprint(soup.find('ul').find_previous('p','title'))\n<p class=\"title\"><b>The Dormouse's story</b></p>\n```", "```py\nprint(soup.find('ul').find_all_previous('p'))\n\n[<p class=\"story\">...</p>, <p class=\"story\">Once upon a time there were three little sisters; and their names were\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\nand they lived at the bottom of a well.</p>, <p class=\"title\"><b>The Dormouse's story</b></p>]\n```", "```py\nprint(soup.find('p','title').next_sibling) #returns empty or new-line\n\nprint(soup.find('p','title').next_sibling.next_sibling) #print(soup.find('p','title').next_sibling.next)\n<p class=\"story\">Once upon a time there were three little sisters; and their names were\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\nand they lived at the bottom of a well.</p>\n\nprint(soup.find('ul').previous_sibling) #returns empty or new-line\n\nprint(soup.find('ul').previous_sibling.previous_sibling)\n<h1>Secret agents</h1>\n```", "```py\n#using List Comprehension \ntitle = [ele.name for ele in soup.find('p','title').next_siblings]\nprint(list(filter(None,title)))\n['p', 'p', 'h1', 'ul']\n\nul = [ele.name for ele in soup.find('ul').previous_siblings]\nprint(list(filter(None,ul)))\n['h1', 'p', 'p', 'p']\n```", "```py\n#find next <p> siblings for selected <p> with class=title\nprint(soup.find('p','title').find_next_siblings('p'))\n[<p class=\"story\">Once upon a time there were three little sisters; and their names were\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\nand they lived at the bottom of a well.</p>, <p class=\"story\">...</p>]\n\n#find single or next sibling for selected <h1>\nprint(soup.find('h1').find_next_sibling())\n<ul>\n<li data-id=\"10784\">Jason Walters, 003: Found dead in \"A View to a Kill\".</li>\n<li data-id=\"97865\">Alex Trevelyan, 006: ............in \"Goldeneye\".</li>\n<li data-id=\"45732\">James Bond, 007: The main man; shaken but not stirred.</li>\n</ul>\n\n#find single or next sibling <li> for selected <h1>\nprint(soup.find('h1').find_next_sibling('li'))\nNone\n```", "```py\n#find first previous sibling to <ul>\nprint(soup.find('ul').find_previous_sibling())\n<h1>Secret agents</h1>\n\n#find all previous siblings to <ul>\nprint(soup.find('ul').find_previous_siblings())\n\n[<h1>Secret agents</h1>, <p class=\"story\">...</p>, <p class=\"story\">Once upon a time there were three little sisters; and their names were\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\nand they lived at the bottom of a well.</p>, <p class=\"title\"><b>The Dormouse's story</b></p>]\n```", "```py\nprint(soup.select('li[data-id]'))\n[<li data-id=\"10784\">Jason Walters, 003: Found dead in \"A View to a Kill\".</li>, <li data-id=\"97865\">Alex Trevelyan, 006: Agent turned terrorist leader; James' nemesis in \"Goldeneye\".</li>, <li data-id=\"45732\">James Bond, 007: The main man; shaken but not stirred.</li>]\n```", "```py\nprint(soup.select('ul li[data-id]')[1]) #fetch index 1 only from resulted List\n<li data-id=\"97865\">Alex Trevelyan, 006: Agent turned terrorist leader; James' nemesis in \"Goldeneye\".</li>\n```", "```py\nprint(soup.select_one('li[data-id]'))\n<li data-id=\"10784\">Jason Walters, 003: Found dead in \"A View to a Kill\".</li>\n```", "```py\nprint(soup.select('p.story > a.sister'))#Selects all <a> with class='sister' that are direct child to <p> with class=\"story\"\n[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n\nprint(soup.select('p b'))#Selects <b> inside <p> [<b>The Dormouse's story</b>]\n\nprint(soup.select('p + h1'))#Selects immediate <h1> after <p>\n[<h1>Secret agents</h1>]\n\nprint(soup.select('p.story + h1'))#Selects immediate <h1> after <p> with class 'story' [<h1>Secret agents</h1>] print(soup.select('p.title + h1'))#Selects immediate <h1> after <p> with class 'title' []\n```", "```py\nprint(soup.select('a[href*=\"example.com\"]'))\n[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n\nprint(soup.select('a[id*=\"link\"]'))\n[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n```", "```py\n''' Listing Quotes from first 5 or less pages found from 'http://quotes.toscrape.com/' '''   import requests\nimport re\nfrom bs4 import BeautifulSoup\nimport csv\n\nsourceUrl = 'http://quotes.toscrape.com/' keys = ['quote_tags','author_url','author_name','born_date','born_location','quote_title']\n```", "```py\ndef read_url(url):\n    \"\"\"Read given Url, Returns requests object for page content\"\"\"\n  response = requests.get(url)\n    return response.text\n```", "```py\nif __name__ == '__main__':\n    dataSet = open('quotes.csv', 'w', newline='', encoding='utf-8')\n    dataWriter = csv.writer(dataSet)\n\n    # Write a Header or Column_names to CSV\n  dataWriter.writerow(keys)\n\n    #load details for provided URL\n    get_details(sourceUrl, dataWriter)\n  dataSet.close()\n```", "```py\ndef get_details(page, dataWriter):\n    \"\"\"Get 'response' for first 5 pages, parse it and collect data for 'keys' headers\"\"\"\n  nextPage = True\n  pageNo = 1\n  while (nextPage and pageNo <= 5):\n        response = read_url(page + 'page/' + str(pageNo))\n        soup = BeautifulSoup(response, 'lxml')\n\n        rows = soup.find_all('div', 'quote')\n        if (len(rows) > 0):\n            print(\"Page \",pageNo,\" Total Quotes Found \",len(rows))\n            for row in rows:\n                if row.find('span',attrs={'itemprop':'text'}):\n                    title = row.find(attrs={'itemprop':'text'}).text.strip()\n                    author = row.find(attrs={'itemprop':'author'}).text.strip()\n                    authorLink = row.find('a',href=re.compile(r'/author/')).get('href')\n                    tags = row.find('div','tags').find(itemprop=\"keywords\").get('content')\n                    print(title, ' : ', author,' : ',authorLink, ' : ',tags)\n\n                    if authorLink:\n                        authorLink = 'http://quotes.toscrape.com' + authorLink\n                        linkDetail = read_url(authorLink)\n                        soupInner = BeautifulSoup(linkDetail, 'lxml')\n                        born_date = soupInner.find('span','author-born-date').text.strip()\n                        born_location = soupInner.find('span','author-born-location').text.strip()\n                        # Write a list of values in file\n  dataWriter.writerow(\n                        [tags,authorLink,author,born_date,born_location.replace('in ',''),title])\n\n            nextPage = True\n  pageNo += 1\n  else:\n            print(\"Quotes Not Listed!\")\n```", "```py\nimport scrapy\n\nclass QuotesSpider(scrapy.Spider):\n    name = \"quotes\"\n    allowed_domains = [\"quotes.toscrape.com\"]\n    start_urls = (\n        'http://www.quotes.toscrape.com/',\n    )\n\n    def parse(self, response):\n        pass\n```", "```py\nstart_urls = ( 'http://quotes.toscrape.com/',)\n```", "```py\nclass QuotesItem(scrapy.Item):\n    # define the fields for your item here like:\n    # name = scrapy.Field()\n\n    quote = scrapy.Field()\n    tags = scrapy.Field()\n    author = scrapy.Field()\n    author_link = scrapy.Field()\n\n    pass\n```", "```py\n#inside Spider 'quotes.py'\nfrom Quotes.items import QuotesItem\n....\n#inside parse()\nitem = QuotesItem() #create an object 'item' and access the fields declared.\n\nitem['quote'] = .......\nitem['tags'] = .......\nitem['author'] = ......\nitem['author_link'] = ......\n......\n```", "```py\n'''\nUsing XPath\n''' def parse(self, response):\n print(\"Response Type >>> \", type(response))\n rows = response.xpath(\"//div[@class='quote']\") #root element\n\n print(\"Quotes Count >> \", rows.__len__())\n for row in rows:\n     item = QuotesItem()\n\n     item['tags'] =     row.xpath('div[@class=\"tags\"]/meta[@itemprop=\"keywords\"]/@content').extract_first().strip()\n     item['author'] = row.xpath('//span/small[@itemprop=\"author\"]/text()').extract_first()\n     item['quote'] = row.xpath('span[@itemprop=\"text\"]/text()').extract_first()\n     item['author_link'] = row.xpath('//a[contains(@href,\"/author/\")]/@href').extract_first()\n\n     if len(item['author_link'])>0:\n         item['author_link'] = 'http://quotes.toscrape.com'+item['author_link']\n\n     yield item\n```", "```py\n'''\nUsing CSS Selectors\n'''\ndef parse(self, response):\n    print(\"Response Type >>> \", type(response))\n    rows = response.css(\"div.quote\") #root element\n\n    for row in rows:\n        item = QuotesItem()\n\n        item['tags'] = row.css('div.tags > meta[itemprop=\"keywords\"]::attr(\"content\")').extract_first()\n        item['author'] = row.css('small[itemprop=\"author\"]::text').extract_first()\n        item['quote'] = row.css('span[itemprop=\"text\"]::text').extract_first()\n        item['author_link'] = row.css('a:contains(\"(about)\")::attr(href)').extract_first()\n\n        if len(item['author_link'])>0:\n            item['author_link'] = 'http://quotes.toscrape.com'+item['author_link']\n\n        yield item   \n```", "```py\ndef parse(self, response):\n    print(\"Response Type >>> \", type(response))\n    rows = response.css(\"div.quote\")\n\n    for row in rows:\n        item = QuotesItem()\n        ......\n        ......\n        yield item\n\n    #using CSS\n    nextPage = response.css(\"ul.pager > li.next > a::attr(href)\").extract_first() \n    #using XPath\n    #nextPage = response.xpath(\"//ul[@class='pager']//li[@class='next']/a/@href\").extract_first()\n\n    if nextPage:\n        print(\"Next Page URL: \",nextPage)\n        #nextPage obtained from either XPath or CSS can be used.\n  yield scrapy.Request('http://quotes.toscrape.com'+nextPage,callback=self.parse)\n\n print('Completed')\n```", "```py\n''' To be used for pagination purpose: include the URL to be used by parse() ''' start_urls = (\n 'http://quotes.toscrape.com/', 'http://quotes.toscrape.com/page/1/', 'http://quotes.toscrape.com/page/2/', )\n```", "```py\nstart_urls = ['http://quotes.toscrape.com/page/%s' % page for page in xrange(1, 6)] '''\nResults to: \n[http://quotes.toscrape.com/page/1,\nhttp://quotes.toscrape.com/page/2,\nhttp://quotes.toscrape.com/page/3,\nhttp://quotes.toscrape.com/page/4,\nhttp://quotes.toscrape.com/page/5,]\n'''\n```", "```py\n...[scrapy] INFO: Scrapy 1.0.3 started (bot: Quotes)\n...[scrapy] INFO: Optional features available: ssl, http11, boto\n...[scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'Quotes.spiders', 'SPIDER_MODULES':     ['Quoyes.spiders'], 'BOT_NAME': 'Quotes'} ....... ...[scrapy] INFO: Enabled item pipelines:\n...[scrapy] INFO: Spider opened\n...[scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n...[scrapy] DEBUG: Telnet console listening on 127.0.0.1:6023\n...[scrapy] DEBUG: Redirecting (301) to <GET http://quotes.toscrape.com/> from <GET http://quotes.toscrape.com/> \n[scrapy] DEBUG: Crawled (200) <GET http://quotes.toscrape.com/page/1/> (referer: None)\n('Response Type >>> ', <class 'scrapy.http.response.html.HtmlResponse'>).......\n.......\n('Response Type >>> ', <class 'scrapy.http.response.html.HtmlResponse'>)\n...[scrapy] DEBUG: Scraped from <200 http://quotes.toscrape.com/>\n{'author': u'J.K. Rowling',\n.......\n...[scrapy] DEBUG: Scraped from <200 http://quotes.toscrape.com/page/5/>\n{'author': u'James Baldwin',\n 'author_link': u'http://quotes.toscrape.com/author/James-Baldwin',\n.....\n('Next Page URL: ', u'/page/6/')\n.......\n.......\nCompleted\n...[scrapy] INFO: Closing spider (finished)  \n```", "```py\n[scrapy] INFO: Dumping Scrapy stats:\n{'downloader/request_bytes': 3316,\n 'downloader/request_count': 13,\n 'downloader/request_method_count/GET': 13,\n 'downloader/response_bytes': 28699,\n 'downloader/response_count': 13,\n 'downloader/response_status_count/200': 11,\n 'downloader/response_status_count/301': 2,\n 'dupefilter/filtered': 1,\n 'finish_reason': 'finished',\n 'finish_time': datetime.datetime(.....\n 'item_scraped_count': 110,\n 'log_count/DEBUG': 126,\n 'log_count/ERROR': 2,\n 'log_count/INFO': 8,\n 'log_count/WARNING': 1,\n 'request_depth_max': 8,\n 'response_received_count': 11,\n 'scheduler/dequeued': 13,\n 'scheduler/dequeued/memory': 13,\n 'scheduler/enqueued': 13,\n 'scheduler/enqueued/memory': 13,\n 'start_time': datetime.datetime(....\n..... [scrapy] INFO: Spider closed (finished)\n```"]