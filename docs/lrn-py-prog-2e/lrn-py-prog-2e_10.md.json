["```py\n$ top\nProcesses: 477 total, 4 running, 473 sleeping, 2234 threads\n...\n```", "```py\n# start.py\nimport threading\n\ndef sum_and_product(a, b):\n    s, p = a + b, a * b\n    print(f'{a}+{b}={s}, {a}*{b}={p}')\n\nt = threading.Thread(\n    target=sum_and_product, name='SumProd', args=(3, 7)\n)\nt.start()\n```", "```py\n$ python start.py\n3+7=10, 3*7=21 \n```", "```py\n# start_with_info.py\nimport threading\nfrom time import sleep\n\ndef sum_and_product(a, b):\n    sleep(.2)\n    print_current()\n    s, p = a + b, a * b\n    print(f'{a}+{b}={s}, {a}*{b}={p}')\n\ndef status(t):\n    if t.is_alive():\n        print(f'Thread {t.name} is alive.')\n    else:\n        print(f'Thread {t.name} has terminated.')\n\ndef print_current():\n    print('The current thread is {}.'.format(\n        threading.current_thread()\n    ))\n    print('Threads: {}'.format(list(threading.enumerate())))\n\nprint_current()\nt = threading.Thread(\n    target=sum_and_product, name='SumPro', args=(3, 7)\n)\nt.start()\nstatus(t)\nt.join()\nstatus(t)\n```", "```py\n$ python start_with_info.py\nThe current thread is\n <_MainThread(MainThread, started 140735733822336)>.\nThreads: [<_MainThread(MainThread, started 140735733822336)>]\nThread SumProd is alive.\nThe current thread is <Thread(SumProd, started 123145375604736)>.\nThreads: [\n <_MainThread(MainThread, started 140735733822336)>,\n <Thread(SumProd, started 123145375604736)>\n]\n3+7=10, 3*7=21\nThread SumProd has terminated.\n```", "```py\n# start_proc.py\nimport multiprocessing\n\n...\n\np = multiprocessing.Process(\n    target=sum_and_product, name='SumProdProc', args=(7, 9)\n)\np.start()\n```", "```py\n# stop.py\nimport threading\nfrom time import sleep\n\nclass Fibo(threading.Thread):\n    def __init__(self, *a, **kwa):\n        super().__init__(*a, **kwa)\n        self._running = True\n\n    def stop(self):\n        self._running = False\n\n    def run(self):\n        a, b = 0, 1\n        while self._running:\n            print(a, end=' ')\n            a, b = b, a + b\n            sleep(0.07)\n        print()\n\nfibo = Fibo()\nfibo.start()\nsleep(1)\nfibo.stop()\nfibo.join()\nprint('All done.')\n```", "```py\n$ python stop.py\n0 1 1 2 3 5 8 13 21 34 55 89 144 233\nAll done.\n```", "```py\n# starwars.py\nimport threading\nfrom time import sleep\nfrom random import random\n\ndef run(n):\n    t = threading.current_thread()\n    for count in range(n):\n        print(f'Hello from {t.name}! ({count})')\n        sleep(0.2 * random())\n\nobi = threading.Thread(target=run, name='Obi-Wan', args=(4, ))\nani = threading.Thread(target=run, name='Anakin', args=(3, ))\nobi.start()\nani.start()\nobi.join()\nani.join()\n```", "```py\n$ python starwars.py\nHello from Obi-Wan! (0)\nHello from Anakin! (0)\nHello from Obi-Wan! (1)\nHello from Obi-Wan! (2)\nHello from Anakin! (1)\nHello from Obi-Wan! (3)\nHello from Anakin! (2)\n```", "```py\n# race.py\nimport threading\nfrom time import sleep\nfrom random import random\n\ncounter = 0\nrandsleep = lambda: sleep(0.1 * random())\n\ndef incr(n):\n    global counter\n    for count in range(n):\n        current = counter\n        randsleep()\n        counter = current + 1\n        randsleep()\n\nn = 5\nt1 = threading.Thread(target=incr, args=(n, ))\nt2 = threading.Thread(target=incr, args=(n, ))\nt1.start()\nt2.start()\nt1.join()\nt2.join()\nprint(f'Counter: {counter}')\n```", "```py\n# race_with_lock.py\nincr_lock = threading.Lock()\n\ndef incr(n):\n    global counter\n    for count in range(n):\n        with incr_lock:\n            current = counter\n            randsleep()\n            counter = current + 1\n            randsleep()\n```", "```py\n# local.py\nimport threading\nfrom random import randint\n\nlocal = threading.local()\n\ndef run(local, barrier):\n    local.my_value = randint(0, 10**2)\n    t = threading.current_thread()\n    print(f'Thread {t.name} has value {local.my_value}')\n    barrier.wait()\n    print(f'Thread {t.name} still has value {local.my_value}')\n\ncount = 3\nbarrier = threading.Barrier(count)\nthreads = [\n    threading.Thread(\n        target=run, name=f'T{name}', args=(local, barrier)\n    ) for name in range(count)\n]\nfor t in threads:\n    t.start()\n```", "```py\n$ python local.py\nThread T0 has value 61\nThread T1 has value 52\nThread T2 has value 38\nThread T2 still has value 38\nThread T0 still has value 61\nThread T1 still has value 52\n```", "```py\n# comm_queue.py\nimport threading\nfrom queue import Queue\n\nSENTINEL = object()\n\ndef producer(q, n):\n    a, b = 0, 1\n    while a <= n:\n        q.put(a)\n        a, b = b, a + b\n    q.put(SENTINEL)\n\ndef consumer(q):\n    while True:\n        num = q.get()\n        q.task_done()\n        if num is SENTINEL:\n            break\n        print(f'Got number {num}')\n\nq = Queue()\ncns = threading.Thread(target=consumer, args=(q, ))\nprd = threading.Thread(target=producer, args=(q, 35))\ncns.start()\nprd.start()\nq.join()\n```", "```py\n# evt.py\nimport threading\n\ndef fire():\n    print('Firing event...')\n    event.set()\n\ndef listen():\n    event.wait()\n    print('Event has been fired')\n\nevent = threading.Event()\nt1 = threading.Thread(target=fire)\nt2 = threading.Thread(target=listen)\nt2.start()\nt1.start()\n```", "```py\n$ python evt.py\nFiring event...\nEvent has been fired\n```", "```py\n# comm_queue_proc.py\nimport multiprocessing\n\nSENTINEL = 'STOP'\n\ndef producer(q, n):\n    a, b = 0, 1\n    while a <= n:\n        q.put(a)\n        a, b = b, a + b\n    q.put(SENTINEL)\n\ndef consumer(q):\n    while True:\n        num = q.get()\n        if num == SENTINEL:\n            break\n        print(f'Got number {num}')\n\nq = multiprocessing.Queue()\ncns = multiprocessing.Process(target=consumer, args=(q, ))\nprd = multiprocessing.Process(target=producer, args=(q, 35))\ncns.start()\nprd.start()\n```", "```py\n# pool.py\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom random import randint\nimport threading\n\ndef run(name):\n    value = randint(0, 10**2)\n    tname = threading.current_thread().name\n    print(f'Hi, I am {name} ({tname}) and my value is {value}')\n    return (name, value)\n\nwith ThreadPoolExecutor(max_workers=3) as executor:\n    futures = [\n        executor.submit(run, f'T{name}') for name in range(5)\n    ]\n    for future in as_completed(futures):\n        name, value = future.result()\n        print(f'Thread {name} returned {value}')\n```", "```py\n$ python pool.py\nHi, I am T0 (ThreadPoolExecutor-0_0) and my value is 5\nHi, I am T1 (ThreadPoolExecutor-0_0) and my value is 23\nHi, I am T2 (ThreadPoolExecutor-0_1) and my value is 58\nThread T1 returned 23\nThread T0 returned 5\nHi, I am T3 (ThreadPoolExecutor-0_0) and my value is 93\nHi, I am T4 (ThreadPoolExecutor-0_1) and my value is 62\nThread T2 returned 58\nThread T3 returned 93\nThread T4 returned 62\n```", "```py\n# pool_proc.py\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nfrom random import randint\nfrom time import sleep\n\ndef run(name):\n    sleep(.05)\n    value = randint(0, 10**2)\n    print(f'Hi, I am {name} and my value is {value}')\n    return (name, value)\n\nwith ProcessPoolExecutor(max_workers=3) as executor:\n    futures = [\n        executor.submit(run, f'P{name}') for name in range(5)\n    ]\n    for future in as_completed(futures):\n        name, value = future.result()\n        print(f'Process {name} returned {value}')\n```", "```py\n$ python pool_proc.py\nHi, I am P0 and my value is 19\nHi, I am P1 and my value is 97\nHi, I am P2 and my value is 74\nProcess P0 returned 19\nProcess P1 returned 97\nProcess P2 returned 74\nHi, I am P3 and my value is 80\nHi, I am P4 and my value is 68\nProcess P3 returned 80\nProcess P4 returned 68\n```", "```py\n# hostres/util.py\nimport socket\nfrom multiprocessing import Process, Queue\n\ndef resolve(hostname, timeout=5):\n    exitcode, ip = resolve_host(hostname, timeout)\n    if exitcode == 0:\n        return ip\n    else:\n        return hostname\n\ndef resolve_host(hostname, timeout):\n    queue = Queue()\n    proc = Process(target=gethostbyname, args=(hostname, queue))\n    proc.start()\n    proc.join(timeout=timeout)\n\n    if queue.empty():\n        proc.terminate()\n        ip = None\n    else:\n        ip = queue.get()\n    return proc.exitcode, ip\n\ndef gethostbyname(hostname, queue):\n    ip = socket.gethostbyname(hostname)\n    queue.put(ip)\n```", "```py\n# ms/algo/mergesort.py\ndef sort(v):\n    if len(v) <= 1:\n        return v\n    mid = len(v) // 2\n    v1, v2 = sort(v[:mid]), sort(v[mid:])\n    return merge(v1, v2)\n\ndef merge(v1, v2):\n    v = []\n    h = k = 0\n    len_v1, len_v2 = len(v1), len(v2)\n    while h < len_v1 or k < len_v2:\n        if k == len_v2 or (h < len_v1 and v1[h] < v2[k]):\n            v.append(v1[h])\n            h += 1\n        else:\n            v.append(v2[k])\n            k += 1\n    return v\n```", "```py\n# ms/algo/multi_mergesort.py\nfrom functools import reduce\nfrom .mergesort import merge\n\ndef sort(v, parts=2):\n    assert parts > 1, 'Parts need to be at least 2.'\n    if len(v) <= 1:\n        return v\n\n    chunk_len = max(1, len(v) // parts)\n    chunks = (\n        sort(v[k: k + chunk_len], parts=parts)\n        for k in range(0, len(v), chunk_len)\n    )\n    return multi_merge(*chunks)\n\ndef multi_merge(*v):\n    return reduce(merge, v)\n```", "```py\n# ms/algo/mergesort_thread.py\nfrom functools import reduce\nfrom math import ceil\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom .mergesort import sort as _sort, merge\n\ndef sort(v, workers=2):\n    if len(v) == 0:\n        return v\n    dim = ceil(len(v) / workers)\n    chunks = (v[k: k + dim] for k in range(0, len(v), dim))\n    with ThreadPoolExecutor(max_workers=workers) as executor:\n        futures = [\n            executor.submit(_sort, chunk) for chunk in chunks\n        ]\n        return reduce(\n            merge,\n            (future.result() for future in as_completed(futures))\n        )\n```", "```py\n# ms/algo/mergesort_proc.py\n...\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\n...\n\ndef sort(v, workers=2):\n    ...\n    with ProcessPoolExecutor(max_workers=workers) as executor:\n    ...\n```", "```py\n$ python performance.py\n\nTesting Sort\nSize: 100000\nElapsed time: 0.492s\nSize: 500000\nElapsed time: 2.739s\n\nTesting Sort Thread\nSize: 100000\nElapsed time: 0.482s\nSize: 500000\nElapsed time: 2.818s\n\nTesting Sort Proc\nSize: 100000\nElapsed time: 0.313s\nSize: 500000\nElapsed time: 1.586s\n```", "```py\n# sudoku/algo/solver.py\nimport os\nfrom itertools import zip_longest, chain\nfrom time import time\n\ndef cross_product(v1, v2):\n    return [w1 + w2 for w1 in v1 for w2 in v2]\n\ndef chunk(iterable, n, fillvalue=None):\n    args = [iter(iterable)] * n\n    return zip_longest(*args, fillvalue=fillvalue)\n```", "```py\ndigits = '123456789'\nrows = 'ABCDEFGHI'\ncols = digits\nsquares = cross_product(rows, cols)\nall_units = (\n    [cross_product(rows, c) for c in cols]\n    + [cross_product(r, cols) for r in rows]\n    + [cross_product(rs, cs)\n        for rs in chunk(rows, 3) for cs in chunk(cols, 3)]\n)\nunits = dict(\n    (square, [unit for unit in all_units if square in unit])\n    for square in squares\n)\npeers = dict(\n    (square, set(chain(*units[square])) - set([square]))\n    for square in squares\n)\n```", "```py\n1..3.......75...3..3.4.8.2...47....9.........689....4..5..178.4.....2.75.......1.\n```", "```py\ndef parse_puzzle(puzzle):\n    assert set(puzzle) <= set('.0123456789')\n    assert len(puzzle) == 81\n\n    grid = dict((square, digits) for square in squares)\n    for square, digit in zip(squares, puzzle):\n        if digit in digits and not place(grid, square, digit):\n            return False  # Incongruent puzzle\n    return grid\n\ndef solve(puzzle):\n    grid = parse_puzzle(puzzle)\n    return search(grid)\n```", "```py\ndef search(grid):\n    if not grid:\n        return False\n    if all(len(grid[square]) == 1 for square in squares):\n        return grid  # Solved\n    values, square = min(\n        (len(grid[square]), square) for square in squares\n        if len(grid[square]) > 1\n    )\n    for digit in grid[square]:\n        result = search(place(grid.copy(), square, digit))\n        if result:\n            return result\n```", "```py\ndef place(grid, square, digit):\n    \"\"\"Eliminate all the other values (except digit) from\n    grid[square] and propagate.\n    Return grid, or False if a contradiction is detected.\n    \"\"\"\n    other_vals = grid[square].replace(digit, '')\n    if all(eliminate(grid, square, val) for val in other_vals):\n        return grid\n    return False\n```", "```py\ndef eliminate(grid, square, digit):\n    \"\"\"Eliminate digit from grid[square]. Propagate when candidates\n    are <= 2.\n    Return grid, or False if a contradiction is detected.\n    \"\"\"\n    if digit not in grid[square]:\n        return grid  # already eliminated\n    grid[square] = grid[square].replace(digit, '')\n\n    ## (1) If a square is reduced to one value, eliminate value\n    ## from peers.\n    if len(grid[square]) == 0:\n        return False  # nothing left to place here, wrong solution\n    elif len(grid[square]) == 1:\n        value = grid[square]\n        if not all(\n            eliminate(grid, peer, value) for peer in peers[square]\n        ):\n            return False\n\n    ## (2) If a unit is reduced to only one place for a value,\n    ## then put it there.\n    for unit in units[square]:\n        places = [sqr for sqr in unit if digit in grid[sqr]]\n        if len(places) == 0:\n            return False  # No place for this value\n        elif len(places) == 1:\n            # digit can only be in one place in unit,\n            # assign it there\n            if not place(grid, places[0], digit):\n                return False\n    return grid\n```", "```py\n# sudoku/process_solver.py\nimport os\nfrom functools import reduce\nfrom operator import concat\nfrom math import ceil\nfrom time import time\nfrom contextlib import contextmanager\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nfrom unittest import TestCase\nfrom algo.solver import solve\n\n@contextmanager\ndef timer():\n    t = time()\n    yield\n    tot = time() - t\n    print(f'Elapsed time: {tot:.3f}s')\n```", "```py\ndef batch_solve(puzzles):\n    # Single thread batch solve.\n    return [solve(puzzle) for puzzle in puzzles]\n```", "```py\ndef parallel_single_solver(puzzles, workers=4):\n    # Parallel solve - 1 process per each puzzle\n    with ProcessPoolExecutor(max_workers=workers) as executor:\n        futures = (\n            executor.submit(solve, puzzle) for puzzle in puzzles\n        )\n        return [\n            future.result() for future in as_completed(futures)\n        ]\n```", "```py\ndef parallel_batch_solver(puzzles, workers=4):\n    # Parallel batch solve - Puzzles are chunked into `workers`\n    # chunks. A process for each chunk.\n    assert len(puzzles) >= workers\n    dim = ceil(len(puzzles) / workers)\n    chunks = (\n        puzzles[k: k + dim] for k in range(0, len(puzzles), dim)\n    )\n    with ProcessPoolExecutor(max_workers=workers) as executor:\n        futures = (\n            executor.submit(batch_solve, chunk) for chunk in chunks\n        )\n        results = (\n            future.result() for future in as_completed(futures)\n        )\n        return reduce(concat, results)\n```", "```py\npuzzles_file = os.path.join('puzzles', 'sudoku-topn234.txt')\nwith open(puzzles_file) as stream:\n    puzzles = [puzzle.strip() for puzzle in stream]\n\n# single thread solve\nwith timer():\n    res_batch = batch_solve(puzzles)\n\n# parallel solve, 1 process per puzzle\nwith timer():\n    res_parallel_single = parallel_single_solver(puzzles)\n\n# parallel batch solve, 1 batch per process\nwith timer():\n    res_parallel_batch = parallel_batch_solver(puzzles)\n\n# Quick way to verify that the results are the same, but\n# possibly in a different order, as they depend on how the\n# processes have been scheduled.\nassert_items_equal = TestCase().assertCountEqual\nassert_items_equal(res_batch, res_parallel_single)\nassert_items_equal(res_batch, res_parallel_batch)\nprint('Done.')\n```", "```py\n$ python process_solver.py\nElapsed time: 5.368s\nElapsed time: 2.856s\nElapsed time: 2.818s\nDone. \n```", "```py\n# aio/randompix_serial.py\nimport os\nfrom secrets import token_hex\nimport requests\n\nPICS_FOLDER = 'pics'\nURL = 'http://lorempixel.com/640/480/'\n\ndef download(url):\n    resp = requests.get(URL)\n    return save_image(resp.content)\n\ndef save_image(content):\n    filename = '{}.jpg'.format(token_hex(4))\n    path = os.path.join(PICS_FOLDER, filename)\n    with open(path, 'wb') as stream:\n        stream.write(content)\n    return filename\n\ndef batch_download(url, n):\n    return [download(url) for _ in range(n)]\n\nif __name__ == '__main__':\n    saved = batch_download(URL, 10)\n    print(saved)\n```", "```py\n# aio/randompix_proc.py\n...\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\n...\n\ndef batch_download(url, n, workers=4):\n    with ProcessPoolExecutor(max_workers=workers) as executor:\n        futures = (executor.submit(download, url) for _ in range(n))\n        return [future.result() for future in as_completed(futures)]\n\n...\n```", "```py\n# aio/randompix_corout.py\nimport os\nfrom secrets import token_hex\nimport asyncio\nimport aiohttp\n```", "```py\nPICS_FOLDER = 'pics'\nURL = 'http://lorempixel.com/640/480/'\n\nasync def download_image(url):\n    async with aiohttp.ClientSession() as session:\n        async with session.get(url) as resp:\n            return await resp.read()\n```", "```py\nasync def download(url, semaphore):\n    async with semaphore:\n        content = await download_image(url)\n    filename = save_image(content)\n    return filename\n\ndef save_image(content):\n    filename = '{}.jpg'.format(token_hex(4))\n    path = os.path.join(PICS_FOLDER, filename)\n    with open(path, 'wb') as stream:\n        stream.write(content)\n    return filename\n```", "```py\ndef batch_download(images, url):\n    loop = asyncio.get_event_loop()\n    semaphore = asyncio.Semaphore(10)\n    cors = [download(url, semaphore) for _ in range(images)]\n    res, _ = loop.run_until_complete(asyncio.wait(cors))\n    loop.close()\n    return [r.result() for r in res]\n\nif __name__ == '__main__':\n    saved = batch_download(20, URL)\n    print(saved)\n```"]