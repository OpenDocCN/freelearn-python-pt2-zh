["```py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\ndataset = pd.read_csv('diabetes.csv')\n```", "```py\ndataset.describe(include='all')\n```", "```py\ndataset.corr()\n```", "```py\n#Split dataset into input(x) and output(y) variables \nx_variables = dataset.iloc[:,0:8]\ny_variable = dataset.iloc[:,8]\n```", "```py\nprint(x_variables)\nprint(y_variable)\n```", "```py\nfrom sklearn.model_selection import train_test_split\nX_train,X_test, y_train,y_test = train_test_split(\n\u00a0\u00a0\u00a0\u00a0x_variables, y_variable, test_size = 0.20, \n\u00a0\u00a0\u00a0\u00a0random_state = 10)\n```", "```py\nfrom sklearn.model_selection import train_test_split\nfrom keras import Sequential from keras.layers import Dense\n#Defining the Model\nmodel = Sequential()\nmodel.add(Dense(12, input_dim=8, activation='relu'))\nmodel.add(Dense(15, activation='relu'))\nmodel.add(Dense(8, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n```", "```py\n#Compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', \n\u00a0\u00a0\u00a0\u00a0metrics=['accuracy'])\n#Fit the model on the dataset\nmodel.fit(x_variables, y_variable, epochs=95, \n\u00a0\u00a0\u00a0\u00a0batch_size=25)\n#Evaluate the model\n_, accuracy = model.evaluate(x_variables, y_variable)\nprint('Accuracy: %.2f' % (accuracy*100))\nmodel.summary()\n```", "```py\nfrom numpy import where\nfrom sklearn.datasets import make_classification\nfrom matplotlib import pyplot\n#Create a synthetic dataset\nX, y = make_classification(n_samples = 1800, \n\u00a0\u00a0\u00a0\u00a0n_features = 2, n_informative = 2, n_redundant = 0, \n\u00a0\u00a0\u00a0\u00a0n_clusters_per_class = 1, random_state=4)\n#Scatterplot\nfor class_value in range(2):\n\trow_ix = where(y == class_value)\n\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\n#Display plot\npyplot.xlabel('variable 1')\npyplot.ylabel('variable 2')\npyplot.title('Synthetic data graph')\npyplot.show()\n```", "```py\nfrom numpy import unique\nfrom numpy import where\nfrom sklearn.datasets import make_classification\nfrom sklearn.cluster import Birch\nfrom matplotlib import pyplot\n#Synthetic dataset definition\nX, _ = make_classification(n_samples = 1800, \n\u00a0\u00a0\u00a0\u00a0n_features = 2, n_informative = 2, n_redundant = 0, \n\u00a0\u00a0\u00a0\u00a0n_clusters_per_class = 1, random_state = 4)\n#Define the BIRCH model\nmodel = Birch(threshold = 0.01, n_clusters = 2)\nmodel.fit(X)\nyhat = model.predict(X)\n#Clusters\nclusters = unique(yhat)\n#Display\nfor cluster in clusters:\n\trow_ix = where(yhat == cluster)\n\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\npyplot.show()\n```", "```py\nmodel = Birch(threshold = 0.01, n_clusters = 3) \n```", "```py\nfrom numpy import unique\nfrom numpy import where\nfrom sklearn.datasets import make_classification\nfrom sklearn.cluster import KMeans\nfrom matplotlib import pyplot\n#Dataset definition\nX, _ = make_classification(n_samples = 1800, \n\u00a0\u00a0\u00a0\u00a0n_features = 2, n_informative = 2, n_redundant = 0, \n\u00a0\u00a0\u00a0\u00a0n_clusters_per_class = 1, random_state = 4)\n#Model identification and fit\nmodel = KMeans(n_clusters = 2)\nmodel.fit(X)\n#Clusters\nyhat = model.predict(X)\nclusters = unique(yhat)\n#Display\nfor cluster in clusters:\n\trow_ix = where(yhat == cluster)\n\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\npyplot.show()\n```"]