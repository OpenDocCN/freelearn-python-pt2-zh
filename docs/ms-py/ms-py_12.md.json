["```py\n**# python3 -m timeit '\"\".join(str(i) for i in range(10000))'**\n**100 loops, best of 3: 2.91 msec per loop**\n**# python2 -m timeit '\"\".join(str(i) for i in range(10000))'**\n**100 loops, best of 3: 2.13 msec per loop**\n**# pypy -m timeit '\"\".join(str(i) for i in range(10000))'**\n**1000 loops, best of 3: 677 usec per loop**\n\n```", "```py\n**# python3 -m timeit 'x=[]; [x.insert(0, i) for i in range(10000)]'**\n**10 loops, best of 3: 30.2 msec per loop**\n**# python3 -m timeit 'x=[]; [x.append(i) for i in range(10000)]'**\n**1000 loops, best of 3: 1.01 msec per loop**\n**# python3 -m timeit 'x=[i for i in range(10000)]'**\n**1000 loops, best of 3: 381 usec per loop**\n**# python3 -m timeit 'x=list(range(10000))'**\n**10000 loops, best of 3: 212 usec per loop**\n\n```", "```py\nimport timeit\n\ndef test_list():\n    return list(range(10000))\n\ndef test_list_comprehension():\n    return [i for i in range(10000)]\n\ndef test_append():\n    x = []\n    for i in range(10000):\n        x.append(i)\n\n    return x\n\ndef test_insert():\n    x = []\n    for i in range(10000):\n        x.insert(0, i)\n\n    return x\n\ndef benchmark(function, number=100, repeat=10):\n    # Measure the execution times\n    times = timeit.repeat(function, number=number, globals=globals())\n    # The repeat function gives `repeat` results so we take the min()\n    # and divide it by the number of runs\n    time = min(times) / number\n    print('%d loops, best of %d: %9.6fs :: %s' % (\n        number, repeat, time, function))\n\nif __name__ == '__main__':\n    benchmark('test_list()')\n    benchmark('test_list_comprehension()')\n    benchmark('test_append()')\n    benchmark('test_insert()')\n```", "```py\n**# python3 test_timeit.py**\n**100 loops, best of 10:  0.000238s :: test_list()**\n**100 loops, best of 10:  0.000407s :: test_list_comprehension()**\n**100 loops, best of 10:  0.000838s :: test_append()**\n**100 loops, best of 10:  0.031795s :: test_insert()**\n\n```", "```py\n**# ipython3**\n**In [1]: import test_timeit**\n**In [2]: %timeit test_timeit.test_list()**\n**1000 loops, best of 3: 255 \u00b5s per loop**\n**In [3]: %timeit test_timeit.test_list_comprehension()**\n**1000 loops, best of 3: 430 \u00b5s per loop**\n**In [4]: %timeit test_timeit.test_append()**\n**1000 loops, best of 3: 934 \u00b5s per loop**\n**In [5]: %timeit test_timeit.test_insert()**\n**10 loops, best of 3: 31.6 ms per loop**\n\n```", "```py\nimport timeit\n\ntimeit.main(args=['[x for x in range(1000000)]'])\n```", "```py\nimport time\nimport functools\n\nTIMEIT_TEMPLATE = '''\nimport time\n\ndef run(number):\n    %(setup)s\n    start = time.perf_counter()\n    for i in range(number):\n        %(statement)s\n    return time.perf_counter() - start\n'''\n\ndef timeit(statement='pass', setup='pass', repeat=1, number=1000000,\n           globals_=None):\n    # Get or create globals\n    globals_ = globals() if globals_ is None else globals_\n\n    # Create the test code so we can separate the namespace\n    src = TIMEIT_TEMPLATE % dict(\n        statement=statement,\n        setup=setup,\n        number=number,\n    )\n    # Compile the source\n    code = compile(src, '<source>', 'exec')\n\n    # Define locals for the benchmarked code\n    locals_ = {}\n\n    # Execute the code so we can get the benchmark fuction\n    exec(code, globals_, locals_)\n\n    # Get the run function\n    run = functools.partial(locals_['run'], number=number)\n    for i in range(repeat):\n        yield run()\n```", "```py\nfrom IPython.core import magic\n\n@magic.register_line_magic(line):\n    import timeit\n    timeit.main(args[line])\n```", "```py\nimport sys\nimport functools\n\n@functools.lru_cache()\ndef fibonacci_cached(n):\n    if n < 2:\n        return n\n    else:\n        return fibonacci_cached(n - 1) + fibonacci_cached(n - 2)\n\ndef fibonacci(n):\n    if n < 2:\n        return n\n    else:\n        return fibonacci(n - 1) + fibonacci(n - 2)\n\nif __name__ == '__main__':\n    n = 30\n    if sys.argv[-1] == 'cache':\n        fibonacci_cached(n)\n    else:\n        fibonacci(n)\n```", "```py\n**# python3 -m cProfile -s calls test_fibonacci.py no_cache**\n **2692557 function calls (21 primitive calls) in 0.815**\n **seconds**\n\n **Ordered by: call count**\n\n **ncalls tottime percall filename:lineno(function)**\n**2692537/1   0.815   0.815 test_fibonacci.py:13(fibonacci)**\n **7   0.000   0.000 {built-in method builtins.getattr}**\n **5   0.000   0.000 {built-in method builtins.setattr}**\n **1   0.000   0.000 {method 'update' of 'dict' objects}**\n **1   0.000   0.000 {built-in method builtins.isinstance}**\n **1   0.000   0.000 functools.py:422(decorating_function)**\n **1   0.000   0.815 test_fibonacci.py:1(<module>)**\n **1   0.000   0.000 {method 'disable' of '_lsprof.Profiler'}**\n **1   0.000   0.815 {built-in method builtins.exec}**\n **1   0.000   0.000 functools.py:43(update_wrapper)**\n        1   0.000   0.000 functools.py:391(lru_cache)\n```", "```py\n**# python3 -m cProfile -s calls test_fibonacci.py cache**\n **51 function calls (21 primitive calls) in 0.000 seconds**\n\n **Ordered by: call count**\n\n **ncalls tottime percall filename:lineno(function)**\n **31/1   0.000   0.000 test_fibonacci.py:5(fibonacci_cached)**\n **7   0.000   0.000 {built-in method builtins.getattr}**\n **5   0.000   0.000 {built-in method builtins.setattr}**\n **1   0.000   0.000 test_fibonacci.py:1(<module>)**\n **1   0.000   0.000 {built-in method builtins.isinstance}**\n **1   0.000   0.000 {built-in method builtins.exec}**\n **1   0.000   0.000 functools.py:422(decorating_function)**\n **1   0.000   0.000 {method 'disable' of '_lsprof.Profiler'}**\n **1   0.000   0.000 {method 'update' of 'dict' objects}**\n **1   0.000   0.000 functools.py:391(lru_cache)**\n **1   0.000   0.000 functools.py:43(update_wrapper)**\n\n```", "```py\n# python3 -m profile -s calls test_fibonacci.py no_cache\n         2692558 function calls (22 primitive calls) in 7.696 seconds\n\n   Ordered by: call count\n\n   ncalls tottime percall filename:lineno(function)\n2692537/1   7.695   7.695 test_fibonacci.py:13(fibonacci)\n        7   0.000   0.000 :0(getattr)\n        5   0.000   0.000 :0(setattr)\n        1   0.000   0.000 :0(isinstance)\n        1   0.001   0.001 :0(setprofile)\n        1   0.000   0.000 :0(update)\n        1   0.000   0.000 functools.py:43(update_wrapper)\n        1   0.000   7.696 profile:0(<code object <module> ...>)\n        1   0.000   7.695 test_fibonacci.py:1(<module>)\n        1   0.000   0.000 functools.py:391(lru_cache)\n        1   0.000   7.695 :0(exec)\n        1   0.000   0.000 functools.py:422(decorating_function)\n        0   0.000         profile:0(profiler)\n```", "```py\nimport profile\n\nif __name__ == '__main__':\n    profiler = profile.Profile()\n    for i in range(10):\n        print(profiler.calibrate(100000))\n```", "```py\nimport profile\n\n# The number here is bias calculated earlier\nprofile.Profile.bias = 2.0939406059394783e-06\n```", "```py\nimport profile\n\nprofiler = profile.Profile(bias=2.0939406059394783e-06)\n```", "```py\nimport sys\nimport pstats\nimport profile\nimport functools\n\n@functools.lru_cache()\ndef fibonacci_cached(n):\n    if n < 2:\n        return n\n    else:\n        return fibonacci_cached(n - 1) + fibonacci_cached(n - 2)\n\ndef fibonacci(n):\n    if n < 2:\n        return n\n    else:\n        return fibonacci(n - 1) + fibonacci(n - 2)\n\nif __name__ == '__main__':\n    profiler = profile.Profile(bias=2.0939406059394783e-06)\n    n = 30\n\n    if sys.argv[-1] == 'cache':\n        profiler.runcall(fibonacci_cached, n)\n    else:\n        profiler.runcall(fibonacci, n)\n\n    stats = pstats.Stats(profiler).sort_stats('calls')\n    stats.print_stats()\n```", "```py\n**# python3 test_fibonacci.py no_cache**\n **2692539 function calls (3 primitive calls) in -0.778**\n **seconds**\n\n **Ordered by: call count**\n\n **ncalls tottime percall filename:lineno(function)**\n**2692537/1  -0.778  -0.778 test_fibonacci.py:15(fibonacci)**\n **1   0.000   0.000 :0(setprofile)**\n **1   0.000  -0.778 profile:0(<function fibonacci at 0x...>)**\n **0   0.000         profile:0(profiler)**\n\n```", "```py\nimport profile\n\nif __name__ == '__main__':\n    profiler = profile.Profile()\n    profiler.bias = profiler.calibrate(100000)\n```", "```py\nimport cProfile\nimport datetime\nimport functools\n\ndef timer(function):\n    @functools.wraps(function)\n    def _timer(*args, **kwargs):\n        start = datetime.datetime.now()\n        try:\n            return function(*args, **kwargs)\n        finally:\n            end = datetime.datetime.now()\n            print('%s: %s' % (function.__name__, end - start))\n    return _timer\n\ndef profiler(function):\n    @functools.wraps(function)\n    def _profiler(*args, **kwargs):\n        profiler = cProfile.Profile()\n        try:\n            profiler.enable()\n            return function(*args, **kwargs)\n        finally:\n            profiler.disable()\n            profiler.print_stats()\n    return _profiler\n\n@profiler\ndef profiled_fibonacci(n):\n    return fibonacci(n)\n\n@timer\ndef timed_fibonacci(n):\n    return fibonacci(n)\n\ndef fibonacci(n):\n    if n < 2:\n        return n\n    else:\n        return fibonacci(n - 1) + fibonacci(n - 2)\n\nif __name__ == '__main__':\n    timed_fibonacci(32)\n    profiled_fibonacci(32)\n```", "```py\n**# python3 test_fibonacci.py**\n **timed_fibonacci: 0:00:01.050200**\n **7049157 function calls (3 primitive calls) in 2.024**\n **seconds**\n\n **Ordered by: standard name**\n\n **ncalls tottime percall filename:lineno(function)**\n **1   0.000   2.024 test_fibonacci.py:31(profiled_fibonacci)**\n**7049155/1   2.024   2.024 test_fibonacci.py:41(fibonacci)**\n **1   0.000   0.000 {method 'disable' of '_lsprof.Profiler'}**\n\n```", "```py\nfrom test import pystone\nimport cProfile\n\nif __name__ == '__main__':\n    profiler = cProfile.Profile()\n    profiler.runcall(pystone.main)\n    profiler.dump_stats('pystone.profile')\n```", "```py\n**# python3 test_pystone.py**\n**Pystone(1.2) time for 50000 passes = 0.725432**\n**This machine benchmarks at 68924.4 pystones/second**\n\n```", "```py\nimport pstats\n\nstats = pstats.Stats('pystone.profile')\nstats.strip_dirs()\nstats.sort_stats('calls', 'cumtime')\nstats.print_stats(10)\n```", "```py\n**# python3 parse_statistics.py**\n\n **1050012 function calls in 0.776 seconds**\n\n **Ordered by: call count, cumulative time**\n **List reduced from 21 to 10 due to restriction <10>**\n\n **ncalls  tottime  percall  cumtime  percall filename:lineno(function)**\n **150000    0.032    0.000    0.032    0.000 pystone.py:214(Proc7)**\n **150000    0.027    0.000    0.027    0.000 pystone.py:232(Func1)**\n **100000    0.016    0.000    0.016    0.000 {built-in method builtins.chr}**\n **100000    0.010    0.000    0.010    0.000 {built-in method builtins.ord}**\n **50002    0.029    0.000    0.029    0.000 pystone.py:52(__init__)**\n **50000    0.127    0.000    0.294    0.000 pystone.py:144(Proc1)**\n **50000    0.094    0.000    0.094    0.000 pystone.py:219(Proc8)**\n **50000    0.048    0.000    0.077    0.000 pystone.py:60(copy)**\n **50000    0.051    0.000    0.061    0.000 pystone.py:240(Func2)**\n **50000    0.031    0.000    0.043    0.000 pystone.py:171(Proc3)**\n\n```", "```py\n**# pyprof2calltree -i pystone.profile -o pystone.callgrind**\n**writing converted data to: pystone.callgrind**\n**# qcachegrind pystone.callgrind**\n\n```", "```py\n **pip install line_profiler**\n\n```", "```py\nimport itertools\n\n@profile\ndef primes():\n    n = 2\n    primes = set()\n    while True:\n        for p in primes:\n            if n % p == 0:\n                break\n        else:\n            primes.add(n)\n            yield n\n        n += 1\n\nif __name__ == '__main__':\n    total = 0\n    n = 2000\n    for prime in itertools.islice(primes(), n):\n        total += prime\n\n    print('The sum of the first %d primes is %d' % (n, total))\n```", "```py\n**# kernprof -l test_primes.py**\n**The sum of the first 2000 primes is 16274627**\n**Wrote profile results to test_primes.py.lprof**\n\n```", "```py\n**# python3 -m line_profiler test_primes.py.lprof**\n**Timer unit: 1e-06 s**\n\n**Total time: 2.33179 s**\n**File: test_primes.py**\n**Function: primes at line 4**\n\n**Line #      Hits   Per Hit   % Time  Line Contents**\n**==================================================**\n **4                               @profile**\n **5                               def primes():**\n **6         1       3.0      0.0      n = 2**\n **7         1       1.0      0.0      primes = set()**\n **8         1       0.0      0.0      while True:**\n **9   2058163       0.5     43.1          for p in primes:**\n **10   2056163       0.6     56.0              if n % p == 0:**\n **11     15388       0.5      0.3                  break**\n **12                                       else:**\n **13      2000       1.2      0.1              primes.add(n)**\n **14      2000       0.5      0.0              yield n**\n **15     17387       0.6      0.4          n += 1**\n\n```", "```py\nIn [1]: a = list(range(1000000))\n\nIn [2]: b = dict.fromkeys(range(1000000))\n\nIn [3]: %timeit 'x' in a\n10 loops, best of 3: 20.5 ms per loop\n\nIn [4]: %timeit 'x' in b\n10000000 loops, best of 3: 41.6 ns per loop\n```", "```py\n**In [1]: %%timeit**\n **...: s = ''**\n **...: for i in range(1000000):**\n **...:     s += str(i)**\n **...:**\n**1 loops, best of 3: 362 ms per loop**\n\n**In [2]: %%timeit**\n **...: ss = []**\n **...: for i in range(1000000):**\n **...:     ss.append(str(i))**\n **...: s = ''.join(ss)**\n **...:**\n**1 loops, best of 3: 332 ms per loop**\n\n**In [3]: %timeit ''.join(str(i) for i in range(1000000))**\n**1 loops, best of 3: 324 ms per loop**\n\n**In [4]: %timeit ''.join([str(i) for i in range(1000000)])**\n**1 loops, best of 3: 294 ms per loop**\n\n```", "```py\nIn [1]: %%timeit\n   ...: x = 0\n   ...: for i in range(1000000):\n   ...:     x += i\n   ...:\n10 loops, best of 3: 73.2 ms per loop\n\nIn [2]: %timeit x = sum(i for i in range(1000000))\n10 loops, best of 3: 75.3 ms per loop\n\nIn [3]: %timeit x = sum([i for i in range(1000000)])\n10 loops, best of 3: 71.2 ms per loop\n\nIn [4]: %timeit x = sum(range(1000000))\n10 loops, best of 3: 25.6 ms per loop\n```", "```py\nIn [1]: %timeit list(map(lambda x: x/2, range(1000000)))\n10 loops, best of 3: 182 ms per loop\n\nIn [2]: %timeit list(x/2 for x in range(1000000))\n10 loops, best of 3: 122 ms per loop\n\nIn [3]: %timeit [x/2 for x in range(1000000)]\n10 loops, best of 3: 84.7 ms per loop\n```", "```py\nIn [1]: import numpy\n\nIn [2]: a = list(range(1000000))\n\nIn [3]: b = numpy.arange(1000000)\n\nIn [4]: %timeit c = [x for x in a if x > 500000]\n10 loops, best of 3: 44 ms per loop\n\nIn [5]: %timeit d = b[b > 500000]\n1000 loops, best of 3: 1.61 ms per loop\n```", "```py\nimport numba\n\n@numba.jit\ndef sum(array):\n    total = 0.0\n    for value in array:\n        total += value\n    return value\n```", "```py\ncdef inline double recip_square(int i):\n    return 1./(i*i)\n\ndef approx_pi(int n=10000000):\n    cdef double val = 0.\n    cdef int k\n    for k in xrange(1,n+1):\n        val += recip_square(k)\n    return (6 * val)**.5\n```", "```py\nimport tracemalloc\n\nif __name__ == '__main__':\n    tracemalloc.start()\n\n    # Reserve some memory\n    x = list(range(1000000))\n\n    # Import some modules\n    import os\n    import sys\n    import asyncio\n\n    # Take a snapshot to calculate the memory usage\n    snapshot = tracemalloc.take_snapshot()\n    for statistic in snapshot.statistics('lineno')[:10]:\n        print(statistic)\n```", "```py\n**# python3 test_tracemalloc.py**\n**test_tracemalloc.py:8: size=35.3 MiB, count=999745, average=37 B**\n**<frozen importlib._bootstrap_external>:473: size=1909 KiB, count=20212, average=97 B**\n**<frozen importlib._bootstrap>:222: size=895 KiB, count=3798, average=241 B**\n**collections/__init__.py:412: size=103 KiB, count=1451, average=72 B**\n**<string>:5: size=36.6 KiB, count=133, average=282 B**\n**collections/__init__.py:406: size=29.9 KiB, count=15, average=2039 B**\n**abc.py:133: size=26.1 KiB, count=102, average=262 B**\n**ipaddress.py:608: size=21.3 KiB, count=182, average=120 B**\n**<frozen importlib._bootstrap_external>:53: size=21.2 KiB, count=140, average=155 B**\n**types.py:234: size=15.3 KiB, count=124, average=127 B**\n\n```", "```py\nimport memory_profiler\n\n@memory_profiler.profile\ndef main():\n    n = 100000\n    a = [i for i in range(n)]\n    b = [i for i in range(n)]\n    c = list(range(n))\n    d = list(range(n))\n    e = dict.fromkeys(a, b)\n    f = dict.fromkeys(c, d)\n\nif __name__ == '__main__':\n    main()\n```", "```py\n**# python3 test_memory_profiler.py**\n**Filename: test_memory_profiler.py**\n\n**Line #    Mem usage    Increment   Line Contents**\n**================================================**\n **4     11.0 MiB      0.0 MiB   @memory_profiler.profile**\n **5                             def main():**\n **6     11.0 MiB      0.0 MiB       n = 100000**\n **7     14.6 MiB      3.5 MiB       a = [i for i in range(n)]**\n **8     17.8 MiB      3.2 MiB       b = [i for i in range(n)]**\n **9     21.7 MiB      3.9 MiB       c = list(range(n))**\n **10     25.5 MiB      3.9 MiB       d = list(range(n))**\n **11     38.0 MiB     12.5 MiB       e = dict.fromkeys(a, b)**\n **12     44.1 MiB      6.1 MiB       f = dict.fromkeys(c, d)**\n\n```", "```py\n 1 import tracemalloc\n 2\n 3\n 4 class Spam(object):\n 5     index = 0\n 6     cache = {}\n 7\n 8     def __init__(self):\n 9         Spam.index += 1\n10         self.cache[Spam.index] = self\n11\n12\n13 class Eggs(object):\n14     eggs = []\n15\n16     def __init__(self):\n17         self.eggs.append(self)\n18\n19\n20 if __name__ == '__main__':\n21     # Initialize some variables to ignore them from the leak\n22     # detection\n23     n = 200000\n24     spam = Spam()\n25\n26     tracemalloc.start()\n27     # Your application should initialize here\n28\n29     snapshot_a = tracemalloc.take_snapshot()\n30     # This code should be the memory leaking part\n31     for i in range(n):\n32         Spam()\n33\n34     Spam.cache = {}\n35     snapshot_b = tracemalloc.take_snapshot()\n36     # And optionally more leaking code here\n37     for i in range(n):\n38         a = Eggs()\n39         b = Eggs()\n40         a.b = b\n41         b.a = a\n42\n43     Eggs.eggs = []\n44     snapshot_c = tracemalloc.take_snapshot()\n45\n46     print('The first leak:')\n47     statistics = snapshot_b.compare_to(snapshot_a, 'lineno')\n48     for statistic in statistics[:10]:\n49         print(statistic)\n50\n51     print('\\nThe second leak:')\n52     statistics = snapshot_c.compare_to(snapshot_b, 'lineno')\n53     for statistic in statistics[:10]:\n54         print(statistic)\n```", "```py\n**# python3 test_leak.py**\n**The first leak:**\n**tracemalloc.py:349: size=528 B (+528 B), count=3 (+3), average=176 B**\n**test_leak.py:34: size=288 B (+288 B), count=2 (+2), average=144 B**\n**test_leak.py:32: size=120 B (+120 B), count=2 (+2), average=60 B**\n**tracemalloc.py:485: size=64 B (+64 B), count=1 (+1), average=64 B**\n**tracemalloc.py:487: size=56 B (+56 B), count=1 (+1), average=56 B**\n**tracemalloc.py:277: size=32 B (+32 B), count=1 (+1), average=32 B**\n**test_leak.py:31: size=28 B (+28 B), count=1 (+1), average=28 B**\n**test_leak.py:9: size=28 B (+28 B), count=1 (+1), average=28 B**\n\n**The second leak:**\n**test_leak.py:41: size=18.3 MiB (+18.3 MiB), count=400000 (+400000), average=48 B**\n**test_leak.py:40: size=18.3 MiB (+18.3 MiB), count=400000 (+400000), average=48 B**\n**test_leak.py:38: size=10.7 MiB (+10.7 MiB), count=200001 (+200001), average=56 B**\n**test_leak.py:39: size=10.7 MiB (+10.7 MiB), count=200002 (+200002), average=56 B**\n**tracemalloc.py:349: size=680 B (+152 B), count=6 (+3), average=113 B**\n**test_leak.py:17: size=72 B (+72 B), count=1 (+1), average=72 B**\n**test_leak.py:43: size=64 B (+64 B), count=1 (+1), average=64 B**\n**test_leak.py:32: size=56 B (-64 B), count=1 (-1), average=56 B**\n**tracemalloc.py:487: size=112 B (+56 B), count=2 (+1), average=56 B**\n**tracemalloc.py:277: size=64 B (+32 B), count=2 (+1), average=32 B**\n\n```", "```py\nimport gc\n\nclass Eggs(object):\n\n    def __init__(self, name):\n        self.name = name\n\n    def __repr__(self):\n        return '<%s: %s>' % (self.__class__.__name__, self.name)\n\n# Create the objects\na = Eggs('a')\nb = Eggs('b')\n\n# Add some circular references\na.b = a\nb.a = b\n\n# Remove the objects\ndel a\ndel b\n\n# See if the objects are still there\nprint('Before manual collection:')\nfor object_ in gc.get_objects():\n    if isinstance(object_, Eggs):\n        print('\\t', object_, gc.get_referents(object_))\n\nprint('After manual collection:')\ngc.collect()\nfor object_ in gc.get_objects():\n    if isinstance(object_, Eggs):\n        print('\\t', object_, gc.get_referents(object_))\n\nprint('Thresholds:', gc.get_threshold())\n```", "```py\n**# python3 test_refcount.py**\n**Before manual collection:**\n **<Eggs: a> [{'b': <Eggs: a>, 'name': 'a'}, <class '__main__.Eggs'>]**\n **<Eggs: b> [{'name': 'b', 'a': <Eggs: b>}, <class '__main__.Eggs'>]**\n**After manual collection:**\n**Thresholds: (700, 10, 10)**\n\n```", "```py\nimport gc\nimport collections\n\nclass Spam(object):\n    index = 0\n    cache = {}\n\n    def __init__(self):\n        Spam.index += 1\n        self.cache[Spam.index] = self\n\nclass Eggs(object):\n    eggs = []\n\n    def __init__(self):\n        self.eggs.append(self)\n\nif __name__ == '__main__':\n    n = 200000\n    for i in range(n):\n        Spam()\n\n    for i in range(n):\n        a = Eggs()\n        b = Eggs()\n        a.b = b\n        b.a = a\n\n    Spam.cache = {}\n    Eggs.eggs = []\n    objects = collections.Counter()\n    for object_ in gc.get_objects():\n        objects[type(object_)] += 1\n\n    for object_, count in objects.most_common(5):\n        print('%d: %s' % (count, object_))\n```", "```py\n**# python3 test_leak.py**\n**400617: <class 'dict'>**\n**400000: <class '__main__.Eggs'>**\n**962: <class 'wrapper_descriptor'>**\n**920: <class 'function'>**\n**625: <class 'method_descriptor'>**\n\n```", "```py\nimport gc\nimport weakref\nimport collections\n\nclass Eggs(object):\n    eggs = []\n\n    def __init__(self):\n        self.eggs.append(self)\n\nif __name__ == '__main__':\n    n = 200000\n    for i in range(n):\n        a = Eggs()\n        b = Eggs()\n        a.b = weakref.ref(b)\n        b.a = weakref.ref(a)\n\n    Eggs.eggs = []\n    objects = collections.Counter()\n    for object_ in gc.get_objects():\n        objects[type(object_)] += 1\n\n    for object_, count in objects.most_common(5):\n        print('%d: %s' % (count, object_))\n```", "```py\n**# python3 test_leak.py**\n**962: <class 'wrapper_descriptor'>**\n**919: <class 'function'>**\n**625: <class 'method_descriptor'>**\n**618: <class 'dict'>**\n**535: <class 'builtin_function_or_method'>**\n\n```", "```py\nimport weakref\n\nclass Eggs(object):\n    pass\n\nif __name__ == '__main__':\n    a = Eggs()\n    b = Eggs()\n    a.b = weakref.ref(b)\n\n    print(a.b())\n    del b\n    print(a.b())\n```", "```py\n**# python3 test_weakref.py**\n**<__main__.Eggs object at 0x104891a20>**\n**None**\n\n```", "```py\n**Line #    Mem usage    Increment   Line Contents**\n**================================================**\n **4     11.0 MiB      0.0 MiB   @memory_profiler.profile**\n **5                             def main():**\n **6     11.0 MiB      0.0 MiB    a = range(1000000)**\n **7     49.7 MiB     38.6 MiB    b = list(range(1000000))**\n\n```", "```py\n**Line #    Mem usage    Increment   Line Contents**\n**================================================**\n **4     11.5 MiB      0.0 MiB   @memory_profiler.profile**\n **5                             def main():**\n **6                             # Generate a huge dict**\n **7     26.3 MiB     14.8 MiB   a = dict.fromkeys(range(100000))**\n **8**\n **9                             # Remove all items**\n **10     26.3 MiB      0.0 MiB   for k in list(a.keys()):**\n **11     26.3 MiB      0.0 MiB   del a[k]**\n **12**\n **13                             # Recreate the dict**\n **14     23.6 MiB     -2.8 MiB   a = dict((k, v) for k, v in a.items())**\n\n```", "```py\nimport memory_profiler\n\nclass Slots(object):\n    __slots__ = 'index', 'name', 'description'\n\n    def __init__(self, index):\n        self.index = index\n        self.name = 'slot %d' % index\n        self.description = 'some slot with index %d' % index\n\nclass NoSlots(object):\n\n    def __init__(self, index):\n        self.index = index\n        self.name = 'slot %d' % index\n        self.description = 'some slot with index %d' % index\n\n@memory_profiler.profile\ndef main():\n    slots = [Slots(i) for i in range(25000)]\n    no_slots = [NoSlots(i) for i in range(25000)]\n    return slots, no_slots\n\nif __name__ == '__main__':\n    main()\n```", "```py\n**# python3 test_slots.py**\n**Filename: test_slots.py**\n\n**Line #    Mem usage    Increment   Line Contents**\n**================================================**\n **21     11.1 MiB      0.0 MiB   @memory_profiler.profile**\n **22                             def main():**\n **23     17.0 MiB      5.9 MiB   slots = [Slots(i) for i in range(25000)]**\n **24     25.0 MiB      8.0 MiB   no_slots = [NoSlots(i) for i in range(25000)]**\n **25     25.0 MiB      0.0 MiB   return slots, no_slots**\n\n```"]