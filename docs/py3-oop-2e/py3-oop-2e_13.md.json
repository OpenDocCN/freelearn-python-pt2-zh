["```py\nfrom threading import Thread\n\nclass InputReader(Thread):\n    def run(self):\n        self.line_of_text = input()\n\nprint(\"Enter some text and press enter: \")\nthread = InputReader()\nthread.start()\n\ncount = result = 1\nwhile thread.is_alive():\n    result = count * count\n    count += 1\n\nprint(\"calculated squares up to {0} * {0} = {1}\".format(\n    count, result))\nprint(\"while you typed '{}'\".format(thread.line_of_text))\n```", "```py\n**Enter some text and press enter:**\n**hello world**\n**calculated squares up to 1044477 * 1044477 = 1090930114576**\n**while you typed 'hello world'**\n\n```", "```py\n**Enter some text and press enter:**\n**hello world**\n**calculated squares up to 1 * 1 = 1**\n**while you typed 'hello world'**\n\n```", "```py\nfrom threading import Thread\nimport json\nfrom urllib.request import urlopen\nimport time\n\nCITIES = [\n    'Edmonton', 'Victoria', 'Winnipeg', 'Fredericton',\n    \"St. John's\", 'Halifax', 'Toronto', 'Charlottetown',\n    'Quebec City', 'Regina'\n]\n\nclass TempGetter(Thread):\n **def __init__(self, city):**\n **super().__init__()**\n **self.city = city**\n\n    def run(self):\n        url_template = (\n            'http://api.openweathermap.org/data/2.5/'\n            'weather?q={},CA&units=metric')\n        response = urlopen(url_template.format(self.city))\n        data = json.loads(response.read().decode())\n        self.temperature = data['main']['temp']\n\n**threads = [TempGetter(c) for c in CITIES]**\nstart = time.time()\nfor thread in threads:\n    thread.start()\n\n**for thread in threads:**\n **thread.join()**\n\nfor thread in threads:\n    print(\n        \"it is {0.temperature:.0f}\u00b0C in {0.city}\".format(thread))\nprint(\n    \"Got {} temps in {} seconds\".format(\n    len(threads), time.time() - start))\n```", "```py\n**it is 5\u00b0C in Edmonton**\n**it is 11\u00b0C in Victoria**\n**it is 0\u00b0C in Winnipeg**\n**it is -10\u00b0C in Fredericton**\n**it is -12\u00b0C in St. John's**\n**it is -8\u00b0C in Halifax**\n**it is -6\u00b0C in Toronto**\n**it is -13\u00b0C in Charlottetown**\n**it is -12\u00b0C in Quebec City**\n**it is 2\u00b0C in Regina**\n **Got 10 temps in 0.18970298767089844 seconds**\n\n```", "```py\nfrom multiprocessing import Process, cpu_count\nimport time\nimport os\n\n**class MuchCPU(Process):**\n    def run(self):\n **print(os.getpid())**\n        for i in range(200000000):\n            pass\n\nif __name__ == '__main__':\n **procs =  [MuchCPU() for f in range(cpu_count())]**\n    t = time.time()\n    for p in procs:\n **p.start()**\n    for p in procs:\n **p.join()**\n    print('work took {} seconds'.format(time.time() - t))\n```", "```py\n**6987**\n**6988**\n**6989**\n**6990**\n**work took 12.96659541130066 seconds**\n\n```", "```py\n**7235**\n**7235**\n**7235**\n**7235**\n**work took 28.577413082122803 seconds**\n\n```", "```py\nimport random\n**from multiprocessing.pool import Pool**\n\ndef prime_factor(value):\n    factors = []\n    for divisor in range(2, value-1):\n        quotient, remainder = divmod(value, divisor)\n        if not remainder:\n            factors.extend(prime_factor(divisor))\n            factors.extend(prime_factor(quotient))\n            break\n    else:\n        factors = [value]\n    return factors\n\nif __name__ == '__main__':\n **pool = Pool()**\n\n    to_factor = [\n        random.randint(100000, 50000000) for i in range(20)\n    ]\n **results = pool.map(prime_factor, to_factor)**\n **for value, factors in zip(to_factor, results):**\n        print(\"The factors of {} are {}\".format(value, factors))\n```", "```py\n**def search(paths, query_q, results_q):**\n    lines = []\n    for path in paths:\n        lines.extend(l.strip() for l in path.open())\n\n **query = query_q.get()**\n    while query:\n **results_q.put([l for l in lines if query in l])**\n **query = query_q.get()**\n\n```", "```py\nif __name__ == '__main__':\n    from multiprocessing import Process, Queue, cpu_count\n    from path import path\n    cpus = cpu_count()\n    pathnames = [f for f in path('.').listdir() if f.isfile()]\n    paths = [pathnames[i::cpus] for i in range(cpus)]\n **query_queues = [Queue() for p in range(cpus)]**\n **results_queue = Queue()**\n\n **search_procs = [**\n **Process(target=search, args=(p, q, results_queue))**\n **for p, q in zip(paths, query_queues)**\n **]**\n    for proc in search_procs: proc.start()\n```", "```py\n    for q in query_queues:\n **q.put(\"def\")**\n **q.put(None)  # Signal process termination**\n\n    for i in range(cpus):\n **for match in results_queue.get():**\n            print(match)\n    for proc in search_procs: proc.join()\n```", "```py\nfrom concurrent.futures import ThreadPoolExecutor\nfrom pathlib import Path\nfrom os.path import sep as pathsep\nfrom collections import deque\n\ndef find_files(path, query_string):\n    subdirs = []\n    for p in path.iterdir():\n        full_path = str(p.absolute())\n        if p.is_dir() and not p.is_symlink():\n            subdirs.append(p)\n        if query_string in full_path:\n                print(full_path)\n\n    return subdirs\n\nquery = '.py'\nfutures = deque()\nbasedir = Path(pathsep).absolute()\n\n**with ThreadPoolExecutor(max_workers=10) as executor:**\n    futures.append(\n        executor.submit(find_files, basedir, query))\n    while futures:\n        future = futures.popleft()\n        if future.exception():\n            continue\n        elif future.done():\n            subdirs = future.result()\n            for subdir in subdirs:\n                futures.append(executor.submit(\n                    find_files, subdir, query))\n        else:\n            futures.append(future)\n```", "```py\n**import asyncio**\nimport random\n\n**@asyncio.coroutine**\ndef random_sleep(counter):\n    delay = random.random() * 5\n    print(\"{} sleeps for {:.2f} seconds\".format(counter, delay))\n **yield from asyncio.sleep(delay)**\n    print(\"{} awakens\".format(counter))\n\n**@asyncio.coroutine**\ndef five_sleepers():\n    print(\"Creating five tasks\")\n **tasks = [**\n **asyncio.async(random_sleep(i)) for i in range(5)]**\n    print(\"Sleeping after starting five tasks\")\n **yield from asyncio.sleep(2)**\n    print(\"Waking and waiting for five tasks\")\n **yield from asyncio.wait(tasks)**\n\n**asyncio.get_event_loop().run_until_complete(five_sleepers())**\nprint(\"Done five tasks\")\n```", "```py\nimport asyncio\nfrom contextlib import suppress\n\nip_map = {\n    b'facebook.com.': '173.252.120.6',\n    b'yougov.com.': '213.52.133.246',\n    b'wipo.int.': '193.5.93.80'\n}\n\ndef lookup_dns(data):\n    domain = b''\n    pointer, part_length = 13, data[12]\n    while part_length:\n        domain += data[pointer:pointer+part_length] + b'.'\n        pointer += part_length + 1\n        part_length = data[pointer - 1]\n\n    ip = ip_map.get(domain, '127.0.0.1')\n\n    return domain, ip\n\ndef create_response(data, ip):\n    ba = bytearray\n    packet = ba(data[:2]) + ba([129, 128]) + data[4:6] * 2\n    packet += ba(4) + data[12:]\n    packet += ba([192, 12, 0, 1, 0, 1, 0, 0, 0, 60, 0, 4])\n    for x in ip.split('.'): packet.append(int(x))\n    return packet\n\n**class DNSProtocol(asyncio.DatagramProtocol):**\n    def connection_made(self, transport):\n        self.transport = transport\n\n **def datagram_received(self, data, addr):**\n        print(\"Received request from {}\".format(addr[0]))\n        domain, ip = lookup_dns(data)\n        print(\"Sending IP {} for {} to {}\".format(\n            domain.decode(), ip, addr[0]))\n **self.transport.sendto(**\n **create_response(data, ip), addr)**\n\nloop = asyncio.get_event_loop()\n**transport, protocol = loop.run_until_complete(**\n **loop.create_datagram_endpoint(**\n **DNSProtocol, local_addr=('127.0.0.1', 4343)))**\nprint(\"DNS Server running\")\n\nwith suppress(KeyboardInterrupt):\n **loop.run_forever()**\n**transport.close()**\n**loop.close()**\n\n```", "```py\n**nslookup -port=4343 facebook.com localhost**\n\n```", "```py\nimport asyncio\nimport json\nfrom concurrent.futures import ProcessPoolExecutor\n\ndef sort_in_process(data):\n    nums = json.loads(data.decode())\n    curr = 1\n    while curr < len(nums):\n        if nums[curr] >= nums[curr-1]:\n            curr += 1\n        else:\n            nums[curr], nums[curr-1] = \\\n                nums[curr-1], nums[curr]\n            if curr > 1:\n                curr -= 1\n\n    return json.dumps(nums).encode()\n\n@asyncio.coroutine\ndef sort_request(reader, writer):\n    print(\"Received connection\")\n **length = yield from reader.read(8)**\n **data = yield from reader.readexactly(**\n **int.from_bytes(length, 'big'))**\n **result = yield from asyncio.get_event_loop().run_in_executor(**\n **None, sort_in_process, data)**\n    print(\"Sorted list\")\n    writer.write(result)\n    writer.close()   \n    print(\"Connection closed\")     \n\nloop = asyncio.get_event_loop()\n**loop.set_default_executor(ProcessPoolExecutor())**\n**server = loop.run_until_complete(**\n **asyncio.start_server(sort_request, '127.0.0.1', 2015))**\nprint(\"Sort Service running\")\n\nloop.run_forever()\nserver.close()\n**loop.run_until_complete(server.wait_closed())**\nloop.close()\n```", "```py\nfrom bitarray import bitarray\ndef compress_chunk(chunk):\n    compressed = bytearray()\n    count = 1\n    last = chunk[0]\n    for bit in chunk[1:]:\n        if bit != last:\n            compressed.append(count | (128 * last))\n            count = 0\n            last = bit\n        count += 1\n    compressed.append(count | (128 * last))\n    return compressed\n```", "```py\ndef compress_row(row):\n    compressed = bytearray()\n    chunks = split_bits(row, 127)\n    for chunk in chunks:\n        compressed.extend(compress_chunk(chunk))\n    return compressed\n```", "```py\ndef split_bits(bits, width):\n    for i in range(0, len(bits), width):\n        yield bits[i:i+width]\n```", "```py\ndef compress_in_executor(executor, bits, width):\n    row_compressors = []\n    for row in split_bits(bits, width):\n **compressor = executor.submit(compress_row, row)**\n        row_compressors.append(compressor)\n\n    compressed = bytearray()\n    for compressor in row_compressors:\n **compressed.extend(compressor.result())**\n    return compressed\n```", "```py\nfrom PIL import Image\ndef compress_image(in_filename, out_filename, executor=None):\n    executor = executor if executor else ProcessPoolExecutor()\n    with Image.open(in_filename) as image:\n        bits = bitarray(image.convert('1').getdata())\n        width, height = image.size\n\n    compressed = compress_in_executor(executor, bits, width)\n\n    with open(out_filename, 'wb') as file:\n        file.write(width.to_bytes(2, 'little'))\n        file.write(height.to_bytes(2, 'little'))\n        file.write(compressed)\n\ndef single_image_main():\n    in_filename, out_filename = sys.argv[1:3]\n    #executor = ThreadPoolExecutor(4)\n **executor = ProcessPoolExecutor()**\n    compress_image(in_filename, out_filename, executor)\n```", "```py\nfrom pathlib import Path\ndef compress_dir(in_dir, out_dir):\n    if not out_dir.exists():\n        out_dir.mkdir()\n\n **executor = ProcessPoolExecutor()**\n    for file in (\n            f for f in in_dir.iterdir() if f.suffix == '.bmp'):\n        out_file = (out_dir / file.name).with_suffix('.rle')\n **executor.submit(**\n **compress_image, str(file), str(out_file))**\n\ndef dir_images_main():\n    in_dir, out_dir = (Path(p) for p in sys.argv[1:3])\n    compress_dir(in_dir, out_dir)\n```", "```py\nfrom PIL import Image\nimport sys\n\ndef decompress(width, height, bytes):\n    image = Image.new('1', (width, height))\n\n    col = 0\n    row = 0\n    for byte in bytes:\n        color = (byte & 128) >> 7\n        count = byte & ~128\n        for i in range(count):\n            image.putpixel((row, col), color)\n            row += 1\n        if not row % width:\n            col += 1\n            row = 0\n    return image\n\nwith open(sys.argv[1], 'rb') as file:\n    width = int.from_bytes(file.read(2), 'little')\n    height = int.from_bytes(file.read(2), 'little')\n\n    image = decompress(width, height, file.read())\n    image.save(sys.argv[2], 'bmp')\n```"]